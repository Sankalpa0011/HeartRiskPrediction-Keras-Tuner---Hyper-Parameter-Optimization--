{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02122a5e",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3324c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam, Adagrad, Adadelta\n",
    "from keras_tuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08d2760",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca4e938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGEIR</th>\n",
       "      <th>TC</th>\n",
       "      <th>HDL</th>\n",
       "      <th>SMOKE_</th>\n",
       "      <th>BPMED</th>\n",
       "      <th>DIAB_01</th>\n",
       "      <th>RISK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>236</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>260</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>187</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>216</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>156</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEX  AGEIR   TC  HDL  SMOKE_  BPMED  DIAB_01  RISK\n",
       "0    2     48  236   66       0      2        0   1.1\n",
       "1    1     48  260   51       0      2        1   7.0\n",
       "2    1     44  187   49       1      2        0   7.0\n",
       "3    2     42  216   57       1      2        0   0.4\n",
       "4    2     56  156   42       0      2        0   2.2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv(\"cardio_dataset.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f35e1f",
   "metadata": {},
   "source": [
    "## Split Target and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52feb784",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.iloc[:,0:7].values\n",
    "target = dataset.iloc[:,7].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b599d92",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21d7e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "target=np.reshape(target, (-1,1))\n",
    "\n",
    "scaler_data = MinMaxScaler(feature_range=(0,1))\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "data_scaled=scaler_data.fit_transform(data)\n",
    "target_scaled=scaler_target.fit_transform(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62961d3",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d6badc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_scaled, target_scaled,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d87e16",
   "metadata": {},
   "source": [
    "## Neural Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692a3bc7",
   "metadata": {},
   "source": [
    "### Keras Tuner ( Hyper Parameter Optimization )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfb59af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(parameters):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(parameters.Int(\"#layers \", 2,20)):      #number of layers gana num_layers kynne.\n",
    "                                                          #2-20 athra random num ekak thorla denwa.10 unth loop eka 10 parak run wnw.\n",
    "        \n",
    "                                                          # palaweni iteration ekedi units wlt random value ekak denwa.\n",
    "                                                          # min 32 and max 512 step eka 32i ethkt 32 , 64 wge 32n 32t random value ekak gnnwa\n",
    "                                                          # parametr choice eke randomly relu sigmoid wge euwa gnnwa.\n",
    "                                                          # i=0 welwata wenma ekk declare krnne palaweni layer eke input dim gana denna oni nisa.\n",
    "        if(i==0):\n",
    "            model.add(Dense(units=parameters.Int(\"#neuron layer \" + str(i), min_value=32, max_value=515, step=32),\n",
    "                            activation=parameters.Choice(\"activation function \" + str(i), [\"relu\", \"sigmoid\", \"tanh\"]), input_dim=7))\n",
    "            \n",
    "            model.add(Dropout(parameters.Choice(\"drop probability \",([0.2, 0.3, 0.4, 0.5]))))    # drop out wltath random probability ekak denwa. \n",
    "            \n",
    "        else:\n",
    "            model.add(Dense(units=parameters.Int(\"#neuron layer \" + str(i), min_value=32, max_value=512, step=32),\n",
    "                           activation=parameters.Choice(\"activation function \" + str(i), [\"relu\", \"sigmoid\", \"tanh\"])))\n",
    "                      \n",
    "            model.add(Dropout(parameters.Choice(\"drop probability \", ([0.2, 0.3, 0.4, 0.5]))))\n",
    "                      \n",
    "    model.add(Dense(1, activation=\"linear\"))              # last layer liner , regression problem nisa.    \n",
    "    \n",
    "    # compile\n",
    "    model.compile(optimizer=parameters.Choice(\"optimizer \", [\"adam\", \"adadelta\", \"adagrad\"]), \n",
    "                  loss=parameters.Choice(\"loss function\", [\"mse\", \"mae\"]))   # random optimizer 3k denwa ekak gnna.\n",
    "                    \n",
    "    # model.compile(optimizer=Adam(parameters.Choice(learning_rate=[1e-2, 1e-3, 1e-4])), loss=\"mse\")\n",
    "    # model.compile(optimizer=AdaDelta(parameters.Choice(learning_rate=[1e-2, 1e-3, 1e-4])), loss=\"mse\")\n",
    "    # model.compile(optimizer=AdaGrade(parameters.Choice(learning_rate=[1e-2, 1e-3, 1e-4])), loss=\"mse\")\n",
    "                      \n",
    "    return model      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "522fb060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from project\\Heart-Risk\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(build_model, objective=\"val_loss\", max_trials=5, executions_per_trial=3, directory=\"project\", \n",
    "                     project_name=\"Heart-Risk\")\n",
    "\n",
    "# tuner means an object from tuner library\n",
    "# build_model kiyanne model ek hdna function eka\n",
    "# regression nisa val_loss e wtrk nwi mean squared error wge oni ekk use krnna puluwan\n",
    "# max_trials means randomly neural netowrk kyk thornwda kyn eka. loku welawak yana nisa 5 damme \n",
    "# eka neural netowrk ek ki parak run krnwd kyn eka\n",
    "# neural netork save wena thena folder name eka project\n",
    "# project name eka define karanawa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df57860c",
   "metadata": {},
   "source": [
    "[more info](https://keras-team.github.io/keras-tuner/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc010740",
   "metadata": {},
   "source": [
    "## Get The Summary\n",
    "#### Can get hypherparameter summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc580962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 36\n",
      "#layers  (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': 'linear'}\n",
      "#neuron layer 0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 515, 'step': 32, 'sampling': 'linear'}\n",
      "activation function 0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
      "drop probability  (Choice)\n",
      "{'default': 0.2, 'conditions': [], 'values': [0.2, 0.3, 0.4, 0.5], 'ordered': True}\n",
      "#neuron layer 1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation function 1 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
      "optimizer  (Choice)\n",
      "{'default': 'adam', 'conditions': [], 'values': ['adam', 'adadelta', 'adagrad'], 'ordered': False}\n",
      "loss function (Choice)\n",
      "{'default': 'mse', 'conditions': [], 'values': ['mse', 'mae'], 'ordered': False}\n",
      "#neuron layer 2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation function 2 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
      "#neuron layer 3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation function 3 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
      "#neuron layer 4 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation function 4 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
      "#neuron layer 5 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation function 5 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
      "#neuron layer 6 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation function 6 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
      "#neuron layer 7 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation function 7 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
      "#neuron layer 8 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation function 8 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
      "#neuron layer 9 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation function 9 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
      "#neuron layer 10 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation function 10 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
      "#neuron layer 11 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation function 11 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
      "#neuron layer 12 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation function 12 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
      "#neuron layer 13 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation function 13 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
      "#neuron layer 14 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation function 14 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
      "#neuron layer 15 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation function 15 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0843a6",
   "metadata": {},
   "source": [
    "## Search Best Parameters For The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bf420a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x_train, y_train, epochs=200, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13942c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in project\\Heart-Risk\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "#layers : 7\n",
      "#neuron layer 0: 288\n",
      "activation function 0: relu\n",
      "drop probability : 0.4\n",
      "#neuron layer 1: 192\n",
      "activation function 1: sigmoid\n",
      "optimizer : adam\n",
      "loss function: mse\n",
      "#neuron layer 2: 480\n",
      "activation function 2: relu\n",
      "#neuron layer 3: 352\n",
      "activation function 3: relu\n",
      "#neuron layer 4: 160\n",
      "activation function 4: relu\n",
      "#neuron layer 5: 64\n",
      "activation function 5: relu\n",
      "#neuron layer 6: 192\n",
      "activation function 6: sigmoid\n",
      "#neuron layer 7: 256\n",
      "activation function 7: sigmoid\n",
      "#neuron layer 8: 96\n",
      "activation function 8: relu\n",
      "#neuron layer 9: 352\n",
      "activation function 9: tanh\n",
      "#neuron layer 10: 192\n",
      "activation function 10: tanh\n",
      "Score: 0.00296808957743148\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "#layers : 9\n",
      "#neuron layer 0: 64\n",
      "activation function 0: tanh\n",
      "drop probability : 0.5\n",
      "#neuron layer 1: 256\n",
      "activation function 1: relu\n",
      "optimizer : adadelta\n",
      "loss function: mse\n",
      "#neuron layer 2: 512\n",
      "activation function 2: relu\n",
      "#neuron layer 3: 96\n",
      "activation function 3: sigmoid\n",
      "#neuron layer 4: 448\n",
      "activation function 4: sigmoid\n",
      "#neuron layer 5: 512\n",
      "activation function 5: tanh\n",
      "#neuron layer 6: 96\n",
      "activation function 6: relu\n",
      "#neuron layer 7: 512\n",
      "activation function 7: sigmoid\n",
      "#neuron layer 8: 288\n",
      "activation function 8: tanh\n",
      "#neuron layer 9: 384\n",
      "activation function 9: sigmoid\n",
      "#neuron layer 10: 480\n",
      "activation function 10: sigmoid\n",
      "#neuron layer 11: 320\n",
      "activation function 11: tanh\n",
      "#neuron layer 12: 64\n",
      "activation function 12: sigmoid\n",
      "#neuron layer 13: 32\n",
      "activation function 13: relu\n",
      "#neuron layer 14: 320\n",
      "activation function 14: tanh\n",
      "#neuron layer 15: 192\n",
      "activation function 15: tanh\n",
      "Score: 0.02112794853746891\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "#layers : 8\n",
      "#neuron layer 0: 320\n",
      "activation function 0: relu\n",
      "drop probability : 0.2\n",
      "#neuron layer 1: 288\n",
      "activation function 1: sigmoid\n",
      "optimizer : adagrad\n",
      "loss function: mse\n",
      "#neuron layer 2: 352\n",
      "activation function 2: sigmoid\n",
      "#neuron layer 3: 480\n",
      "activation function 3: relu\n",
      "#neuron layer 4: 480\n",
      "activation function 4: tanh\n",
      "#neuron layer 5: 64\n",
      "activation function 5: relu\n",
      "#neuron layer 6: 512\n",
      "activation function 6: relu\n",
      "#neuron layer 7: 128\n",
      "activation function 7: tanh\n",
      "#neuron layer 8: 192\n",
      "activation function 8: sigmoid\n",
      "#neuron layer 9: 224\n",
      "activation function 9: relu\n",
      "#neuron layer 10: 512\n",
      "activation function 10: tanh\n",
      "#neuron layer 11: 512\n",
      "activation function 11: relu\n",
      "#neuron layer 12: 160\n",
      "activation function 12: tanh\n",
      "#neuron layer 13: 480\n",
      "activation function 13: relu\n",
      "#neuron layer 14: 480\n",
      "activation function 14: sigmoid\n",
      "#neuron layer 15: 416\n",
      "activation function 15: relu\n",
      "Score: 0.021137872089942295\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "#layers : 11\n",
      "#neuron layer 0: 480\n",
      "activation function 0: tanh\n",
      "drop probability : 0.4\n",
      "#neuron layer 1: 64\n",
      "activation function 1: relu\n",
      "optimizer : adadelta\n",
      "loss function: mse\n",
      "#neuron layer 2: 32\n",
      "activation function 2: relu\n",
      "#neuron layer 3: 32\n",
      "activation function 3: relu\n",
      "#neuron layer 4: 32\n",
      "activation function 4: relu\n",
      "#neuron layer 5: 32\n",
      "activation function 5: relu\n",
      "#neuron layer 6: 32\n",
      "activation function 6: relu\n",
      "#neuron layer 7: 32\n",
      "activation function 7: relu\n",
      "#neuron layer 8: 32\n",
      "activation function 8: relu\n",
      "#neuron layer 9: 32\n",
      "activation function 9: relu\n",
      "#neuron layer 10: 32\n",
      "activation function 10: relu\n",
      "Score: 0.0217495895922184\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "#layers : 16\n",
      "#neuron layer 0: 352\n",
      "activation function 0: relu\n",
      "drop probability : 0.4\n",
      "#neuron layer 1: 320\n",
      "activation function 1: relu\n",
      "optimizer : adam\n",
      "loss function: mae\n",
      "#neuron layer 2: 160\n",
      "activation function 2: relu\n",
      "#neuron layer 3: 512\n",
      "activation function 3: relu\n",
      "#neuron layer 4: 128\n",
      "activation function 4: relu\n",
      "#neuron layer 5: 352\n",
      "activation function 5: tanh\n",
      "#neuron layer 6: 320\n",
      "activation function 6: relu\n",
      "#neuron layer 7: 128\n",
      "activation function 7: relu\n",
      "#neuron layer 8: 224\n",
      "activation function 8: relu\n",
      "#neuron layer 9: 128\n",
      "activation function 9: tanh\n",
      "#neuron layer 10: 224\n",
      "activation function 10: tanh\n",
      "#neuron layer 11: 32\n",
      "activation function 11: relu\n",
      "#neuron layer 12: 32\n",
      "activation function 12: relu\n",
      "#neuron layer 13: 32\n",
      "activation function 13: relu\n",
      "#neuron layer 14: 32\n",
      "activation function 14: relu\n",
      "#neuron layer 15: 32\n",
      "activation function 15: relu\n",
      "Score: 0.08693820238113403\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()                             # dropout probabilities and activation functions details can get here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43fa240d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 34 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">55,488</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">92,640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">169,312</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">56,480</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,480</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)                 │           \u001b[38;5;34m2,304\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                 │          \u001b[38;5;34m55,488\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)                 │          \u001b[38;5;34m92,640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m352\u001b[0m)                 │         \u001b[38;5;34m169,312\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m352\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)                 │          \u001b[38;5;34m56,480\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m10,304\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                 │          \u001b[38;5;34m12,480\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m193\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">399,201</span> (1.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m399,201\u001b[0m (1.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">399,201</span> (1.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m399,201\u001b[0m (1.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: None \n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models()\n",
    "print(f\"Best Model: {best_model[0].summary()} \")    # Layers details can get here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a985a3b9",
   "metadata": {},
   "source": [
    "## Neuran Network Architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef5c4ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">55,488</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">92,640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">169,312</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">56,480</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,480</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)                 │           \u001b[38;5;34m2,304\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                 │          \u001b[38;5;34m55,488\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)                 │          \u001b[38;5;34m92,640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m352\u001b[0m)                 │         \u001b[38;5;34m169,312\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m352\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)                 │          \u001b[38;5;34m56,480\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m10,304\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                 │          \u001b[38;5;34m12,480\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m193\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">399,201</span> (1.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m399,201\u001b[0m (1.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">399,201</span> (1.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m399,201\u001b[0m (1.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(288, input_dim=7, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(192, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(480, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(352, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(160, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(192, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mse\", \"mae\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e0182c",
   "metadata": {},
   "source": [
    "## Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fe4a533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0725 - mae: 0.1859 - mse: 0.0725 - val_loss: 0.0312 - val_mae: 0.1167 - val_mse: 0.0312\n",
      "Epoch 2/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0300 - mae: 0.1219 - mse: 0.0300 - val_loss: 0.0074 - val_mae: 0.0545 - val_mse: 0.0074\n",
      "Epoch 3/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0129 - mae: 0.0748 - mse: 0.0129 - val_loss: 0.0066 - val_mae: 0.0522 - val_mse: 0.0066\n",
      "Epoch 4/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0108 - mae: 0.0690 - mse: 0.0108 - val_loss: 0.0055 - val_mae: 0.0485 - val_mse: 0.0055\n",
      "Epoch 5/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0097 - mae: 0.0659 - mse: 0.0097 - val_loss: 0.0051 - val_mae: 0.0491 - val_mse: 0.0051\n",
      "Epoch 6/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0087 - mae: 0.0641 - mse: 0.0087 - val_loss: 0.0054 - val_mae: 0.0467 - val_mse: 0.0054\n",
      "Epoch 7/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - mae: 0.0618 - mse: 0.0082 - val_loss: 0.0046 - val_mae: 0.0442 - val_mse: 0.0046\n",
      "Epoch 8/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - mae: 0.0607 - mse: 0.0084 - val_loss: 0.0045 - val_mae: 0.0441 - val_mse: 0.0045\n",
      "Epoch 9/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0069 - mae: 0.0574 - mse: 0.0069 - val_loss: 0.0042 - val_mae: 0.0415 - val_mse: 0.0042\n",
      "Epoch 10/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0073 - mae: 0.0576 - mse: 0.0073 - val_loss: 0.0044 - val_mae: 0.0432 - val_mse: 0.0044\n",
      "Epoch 11/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0059 - mae: 0.0519 - mse: 0.0059 - val_loss: 0.0044 - val_mae: 0.0455 - val_mse: 0.0044\n",
      "Epoch 12/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0057 - mae: 0.0509 - mse: 0.0057 - val_loss: 0.0044 - val_mae: 0.0411 - val_mse: 0.0044\n",
      "Epoch 13/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0059 - mae: 0.0498 - mse: 0.0059 - val_loss: 0.0047 - val_mae: 0.0443 - val_mse: 0.0047\n",
      "Epoch 14/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0062 - mae: 0.0519 - mse: 0.0062 - val_loss: 0.0042 - val_mae: 0.0436 - val_mse: 0.0042\n",
      "Epoch 15/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0052 - mae: 0.0488 - mse: 0.0052 - val_loss: 0.0039 - val_mae: 0.0388 - val_mse: 0.0039\n",
      "Epoch 16/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0055 - mae: 0.0495 - mse: 0.0055 - val_loss: 0.0042 - val_mae: 0.0407 - val_mse: 0.0042\n",
      "Epoch 17/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0054 - mae: 0.0477 - mse: 0.0054 - val_loss: 0.0038 - val_mae: 0.0394 - val_mse: 0.0038\n",
      "Epoch 18/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0050 - mae: 0.0484 - mse: 0.0050 - val_loss: 0.0039 - val_mae: 0.0417 - val_mse: 0.0039\n",
      "Epoch 19/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0052 - mae: 0.0486 - mse: 0.0052 - val_loss: 0.0046 - val_mae: 0.0417 - val_mse: 0.0046\n",
      "Epoch 20/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0050 - mae: 0.0468 - mse: 0.0050 - val_loss: 0.0036 - val_mae: 0.0389 - val_mse: 0.0036\n",
      "Epoch 21/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0045 - mae: 0.0450 - mse: 0.0045 - val_loss: 0.0045 - val_mae: 0.0416 - val_mse: 0.0045\n",
      "Epoch 22/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0053 - mae: 0.0468 - mse: 0.0053 - val_loss: 0.0037 - val_mae: 0.0399 - val_mse: 0.0037\n",
      "Epoch 23/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0049 - mae: 0.0466 - mse: 0.0049 - val_loss: 0.0040 - val_mae: 0.0400 - val_mse: 0.0040\n",
      "Epoch 24/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0051 - mae: 0.0461 - mse: 0.0051 - val_loss: 0.0041 - val_mae: 0.0393 - val_mse: 0.0041\n",
      "Epoch 25/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0048 - mae: 0.0459 - mse: 0.0048 - val_loss: 0.0037 - val_mae: 0.0390 - val_mse: 0.0037\n",
      "Epoch 26/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0050 - mae: 0.0458 - mse: 0.0050 - val_loss: 0.0039 - val_mae: 0.0398 - val_mse: 0.0039\n",
      "Epoch 27/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0454 - mse: 0.0049 - val_loss: 0.0041 - val_mae: 0.0398 - val_mse: 0.0041\n",
      "Epoch 28/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0054 - mae: 0.0480 - mse: 0.0054 - val_loss: 0.0037 - val_mae: 0.0389 - val_mse: 0.0037\n",
      "Epoch 29/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0051 - mae: 0.0462 - mse: 0.0051 - val_loss: 0.0039 - val_mae: 0.0401 - val_mse: 0.0039\n",
      "Epoch 30/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0049 - mae: 0.0465 - mse: 0.0049 - val_loss: 0.0038 - val_mae: 0.0395 - val_mse: 0.0038\n",
      "Epoch 31/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0043 - mae: 0.0441 - mse: 0.0043 - val_loss: 0.0038 - val_mae: 0.0394 - val_mse: 0.0038\n",
      "Epoch 32/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0041 - mae: 0.0441 - mse: 0.0041 - val_loss: 0.0038 - val_mae: 0.0390 - val_mse: 0.0038\n",
      "Epoch 33/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0043 - mae: 0.0439 - mse: 0.0043 - val_loss: 0.0040 - val_mae: 0.0397 - val_mse: 0.0040\n",
      "Epoch 34/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0043 - mae: 0.0443 - mse: 0.0043 - val_loss: 0.0037 - val_mae: 0.0396 - val_mse: 0.0037\n",
      "Epoch 35/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0044 - mae: 0.0427 - mse: 0.0044 - val_loss: 0.0038 - val_mae: 0.0424 - val_mse: 0.0038\n",
      "Epoch 36/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0041 - mae: 0.0438 - mse: 0.0041 - val_loss: 0.0041 - val_mae: 0.0398 - val_mse: 0.0041\n",
      "Epoch 37/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0043 - mae: 0.0427 - mse: 0.0043 - val_loss: 0.0038 - val_mae: 0.0389 - val_mse: 0.0038\n",
      "Epoch 38/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0046 - mae: 0.0443 - mse: 0.0046 - val_loss: 0.0041 - val_mae: 0.0392 - val_mse: 0.0041\n",
      "Epoch 39/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0044 - mae: 0.0439 - mse: 0.0044 - val_loss: 0.0035 - val_mae: 0.0375 - val_mse: 0.0035\n",
      "Epoch 40/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0041 - mae: 0.0423 - mse: 0.0041 - val_loss: 0.0037 - val_mae: 0.0409 - val_mse: 0.0037\n",
      "Epoch 41/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0045 - mae: 0.0437 - mse: 0.0045 - val_loss: 0.0036 - val_mae: 0.0376 - val_mse: 0.0036\n",
      "Epoch 42/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0049 - mae: 0.0453 - mse: 0.0049 - val_loss: 0.0036 - val_mae: 0.0387 - val_mse: 0.0036\n",
      "Epoch 43/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0040 - mae: 0.0425 - mse: 0.0040 - val_loss: 0.0041 - val_mae: 0.0391 - val_mse: 0.0041\n",
      "Epoch 44/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0406 - mse: 0.0038 - val_loss: 0.0039 - val_mae: 0.0394 - val_mse: 0.0039\n",
      "Epoch 45/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0041 - mae: 0.0421 - mse: 0.0041 - val_loss: 0.0035 - val_mae: 0.0378 - val_mse: 0.0035\n",
      "Epoch 46/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0428 - mse: 0.0042 - val_loss: 0.0039 - val_mae: 0.0405 - val_mse: 0.0039\n",
      "Epoch 47/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0428 - mse: 0.0042 - val_loss: 0.0038 - val_mae: 0.0381 - val_mse: 0.0038\n",
      "Epoch 48/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0421 - mse: 0.0042 - val_loss: 0.0036 - val_mae: 0.0381 - val_mse: 0.0036\n",
      "Epoch 49/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0426 - mse: 0.0042 - val_loss: 0.0036 - val_mae: 0.0403 - val_mse: 0.0036\n",
      "Epoch 50/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0444 - mse: 0.0042 - val_loss: 0.0037 - val_mae: 0.0387 - val_mse: 0.0037\n",
      "Epoch 51/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0041 - mae: 0.0425 - mse: 0.0041 - val_loss: 0.0038 - val_mae: 0.0385 - val_mse: 0.0038\n",
      "Epoch 52/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0040 - mae: 0.0425 - mse: 0.0040 - val_loss: 0.0038 - val_mae: 0.0386 - val_mse: 0.0038\n",
      "Epoch 53/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0417 - mse: 0.0042 - val_loss: 0.0038 - val_mae: 0.0384 - val_mse: 0.0038\n",
      "Epoch 54/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0408 - mse: 0.0039 - val_loss: 0.0036 - val_mae: 0.0376 - val_mse: 0.0036\n",
      "Epoch 55/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0040 - mae: 0.0420 - mse: 0.0040 - val_loss: 0.0036 - val_mae: 0.0373 - val_mse: 0.0036\n",
      "Epoch 56/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0041 - mae: 0.0418 - mse: 0.0041 - val_loss: 0.0039 - val_mae: 0.0393 - val_mse: 0.0039\n",
      "Epoch 57/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0041 - mae: 0.0421 - mse: 0.0041 - val_loss: 0.0034 - val_mae: 0.0368 - val_mse: 0.0034\n",
      "Epoch 58/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0043 - mae: 0.0425 - mse: 0.0043 - val_loss: 0.0034 - val_mae: 0.0369 - val_mse: 0.0034\n",
      "Epoch 59/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0040 - mae: 0.0417 - mse: 0.0040 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 60/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0408 - mse: 0.0039 - val_loss: 0.0037 - val_mae: 0.0385 - val_mse: 0.0037\n",
      "Epoch 61/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0397 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0378 - val_mse: 0.0034\n",
      "Epoch 62/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0413 - mse: 0.0039 - val_loss: 0.0034 - val_mae: 0.0370 - val_mse: 0.0034\n",
      "Epoch 63/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0412 - mse: 0.0038 - val_loss: 0.0038 - val_mae: 0.0378 - val_mse: 0.0038\n",
      "Epoch 64/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0398 - mse: 0.0037 - val_loss: 0.0039 - val_mae: 0.0382 - val_mse: 0.0039\n",
      "Epoch 65/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0040 - mae: 0.0415 - mse: 0.0040 - val_loss: 0.0034 - val_mae: 0.0374 - val_mse: 0.0034\n",
      "Epoch 66/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0405 - mse: 0.0038 - val_loss: 0.0036 - val_mae: 0.0396 - val_mse: 0.0036\n",
      "Epoch 67/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0413 - mse: 0.0039 - val_loss: 0.0036 - val_mae: 0.0371 - val_mse: 0.0036\n",
      "Epoch 68/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0403 - mse: 0.0039 - val_loss: 0.0037 - val_mae: 0.0385 - val_mse: 0.0037\n",
      "Epoch 69/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0041 - mae: 0.0417 - mse: 0.0041 - val_loss: 0.0037 - val_mae: 0.0375 - val_mse: 0.0037\n",
      "Epoch 70/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0041 - mae: 0.0409 - mse: 0.0041 - val_loss: 0.0036 - val_mae: 0.0376 - val_mse: 0.0036\n",
      "Epoch 71/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0405 - mse: 0.0039 - val_loss: 0.0035 - val_mae: 0.0369 - val_mse: 0.0035\n",
      "Epoch 72/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0393 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0374 - val_mse: 0.0034\n",
      "Epoch 73/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0402 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0384 - val_mse: 0.0035\n",
      "Epoch 74/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0404 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0372 - val_mse: 0.0034\n",
      "Epoch 75/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0401 - mse: 0.0037 - val_loss: 0.0033 - val_mae: 0.0366 - val_mse: 0.0033\n",
      "Epoch 76/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0401 - mse: 0.0038 - val_loss: 0.0034 - val_mae: 0.0372 - val_mse: 0.0034\n",
      "Epoch 77/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0412 - mse: 0.0039 - val_loss: 0.0035 - val_mae: 0.0364 - val_mse: 0.0035\n",
      "Epoch 78/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0399 - mse: 0.0038 - val_loss: 0.0037 - val_mae: 0.0376 - val_mse: 0.0037\n",
      "Epoch 79/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0401 - mse: 0.0038 - val_loss: 0.0034 - val_mae: 0.0370 - val_mse: 0.0034\n",
      "Epoch 80/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0407 - mse: 0.0039 - val_loss: 0.0033 - val_mae: 0.0362 - val_mse: 0.0033\n",
      "Epoch 81/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0040 - mae: 0.0411 - mse: 0.0040 - val_loss: 0.0035 - val_mae: 0.0389 - val_mse: 0.0035\n",
      "Epoch 82/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0040 - mae: 0.0424 - mse: 0.0040 - val_loss: 0.0035 - val_mae: 0.0372 - val_mse: 0.0035\n",
      "Epoch 83/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0403 - mse: 0.0039 - val_loss: 0.0037 - val_mae: 0.0373 - val_mse: 0.0037\n",
      "Epoch 84/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0413 - mse: 0.0039 - val_loss: 0.0037 - val_mae: 0.0383 - val_mse: 0.0037\n",
      "Epoch 85/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0390 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0373 - val_mse: 0.0037\n",
      "Epoch 86/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0394 - mse: 0.0037 - val_loss: 0.0038 - val_mae: 0.0375 - val_mse: 0.0038\n",
      "Epoch 87/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0400 - mse: 0.0039 - val_loss: 0.0034 - val_mae: 0.0374 - val_mse: 0.0034\n",
      "Epoch 88/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0395 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0362 - val_mse: 0.0034\n",
      "Epoch 89/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0393 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0373 - val_mse: 0.0035\n",
      "Epoch 90/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0403 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0375 - val_mse: 0.0035\n",
      "Epoch 91/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0399 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0362 - val_mse: 0.0035\n",
      "Epoch 92/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0406 - mse: 0.0038 - val_loss: 0.0034 - val_mae: 0.0359 - val_mse: 0.0034\n",
      "Epoch 93/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0390 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0382 - val_mse: 0.0036\n",
      "Epoch 94/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0395 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0376 - val_mse: 0.0036\n",
      "Epoch 95/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0396 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0359 - val_mse: 0.0035\n",
      "Epoch 96/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0402 - mse: 0.0038 - val_loss: 0.0036 - val_mae: 0.0363 - val_mse: 0.0036\n",
      "Epoch 97/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0378 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 98/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0402 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0364 - val_mse: 0.0034\n",
      "Epoch 99/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0393 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 100/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0390 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0364 - val_mse: 0.0035\n",
      "Epoch 101/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0379 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0368 - val_mse: 0.0034\n",
      "Epoch 102/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0393 - mse: 0.0036 - val_loss: 0.0033 - val_mae: 0.0360 - val_mse: 0.0033\n",
      "Epoch 103/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0387 - mse: 0.0036 - val_loss: 0.0033 - val_mae: 0.0364 - val_mse: 0.0033\n",
      "Epoch 104/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0402 - mse: 0.0038 - val_loss: 0.0034 - val_mae: 0.0368 - val_mse: 0.0034\n",
      "Epoch 105/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0390 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0359 - val_mse: 0.0036\n",
      "Epoch 106/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0395 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0367 - val_mse: 0.0036\n",
      "Epoch 107/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0393 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0360 - val_mse: 0.0035\n",
      "Epoch 108/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0388 - mse: 0.0035 - val_loss: 0.0033 - val_mae: 0.0361 - val_mse: 0.0033\n",
      "Epoch 109/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0417 - mse: 0.0039 - val_loss: 0.0035 - val_mae: 0.0385 - val_mse: 0.0035\n",
      "Epoch 110/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0409 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0368 - val_mse: 0.0034\n",
      "Epoch 111/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0396 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0372 - val_mse: 0.0034\n",
      "Epoch 112/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0393 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0363 - val_mse: 0.0035\n",
      "Epoch 113/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0406 - mse: 0.0039 - val_loss: 0.0039 - val_mae: 0.0372 - val_mse: 0.0039\n",
      "Epoch 114/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0394 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0359 - val_mse: 0.0035\n",
      "Epoch 115/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0374 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0373 - val_mse: 0.0034\n",
      "Epoch 116/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0401 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0362 - val_mse: 0.0034\n",
      "Epoch 117/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0397 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0369 - val_mse: 0.0034\n",
      "Epoch 118/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0373 - mse: 0.0032 - val_loss: 0.0036 - val_mae: 0.0378 - val_mse: 0.0036\n",
      "Epoch 119/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0402 - mse: 0.0038 - val_loss: 0.0035 - val_mae: 0.0373 - val_mse: 0.0035\n",
      "Epoch 120/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0373 - mse: 0.0033 - val_loss: 0.0040 - val_mae: 0.0388 - val_mse: 0.0040\n",
      "Epoch 121/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0380 - mse: 0.0034 - val_loss: 0.0038 - val_mae: 0.0404 - val_mse: 0.0038\n",
      "Epoch 122/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0393 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0366 - val_mse: 0.0035\n",
      "Epoch 123/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0396 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0374 - val_mse: 0.0035\n",
      "Epoch 124/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0031 - mae: 0.0370 - mse: 0.0031 - val_loss: 0.0035 - val_mae: 0.0363 - val_mse: 0.0035\n",
      "Epoch 125/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0386 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0375 - val_mse: 0.0034\n",
      "Epoch 126/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0390 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0367 - val_mse: 0.0034\n",
      "Epoch 127/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0378 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0368 - val_mse: 0.0033\n",
      "Epoch 128/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0386 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0367 - val_mse: 0.0035\n",
      "Epoch 129/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0398 - mse: 0.0037 - val_loss: 0.0037 - val_mae: 0.0383 - val_mse: 0.0037\n",
      "Epoch 130/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0385 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0373 - val_mse: 0.0034\n",
      "Epoch 131/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0377 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0376 - val_mse: 0.0034\n",
      "Epoch 132/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0400 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0367 - val_mse: 0.0034\n",
      "Epoch 133/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0389 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0367 - val_mse: 0.0035\n",
      "Epoch 134/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0394 - mse: 0.0035 - val_loss: 0.0037 - val_mae: 0.0377 - val_mse: 0.0037\n",
      "Epoch 135/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0400 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0367 - val_mse: 0.0036\n",
      "Epoch 136/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0384 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0366 - val_mse: 0.0034\n",
      "Epoch 137/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0393 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0366 - val_mse: 0.0036\n",
      "Epoch 138/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0373 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0370 - val_mse: 0.0034\n",
      "Epoch 139/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0396 - mse: 0.0038 - val_loss: 0.0039 - val_mae: 0.0380 - val_mse: 0.0039\n",
      "Epoch 140/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0397 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0370 - val_mse: 0.0036\n",
      "Epoch 141/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0381 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0366 - val_mse: 0.0035\n",
      "Epoch 142/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0380 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0361 - val_mse: 0.0035\n",
      "Epoch 143/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0378 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0359 - val_mse: 0.0034\n",
      "Epoch 144/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0389 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0356 - val_mse: 0.0034\n",
      "Epoch 145/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0370 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0365 - val_mse: 0.0035\n",
      "Epoch 146/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0380 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0357 - val_mse: 0.0035\n",
      "Epoch 147/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0384 - mse: 0.0036 - val_loss: 0.0033 - val_mae: 0.0360 - val_mse: 0.0033\n",
      "Epoch 148/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0375 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0367 - val_mse: 0.0034\n",
      "Epoch 149/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0384 - mse: 0.0035 - val_loss: 0.0037 - val_mae: 0.0366 - val_mse: 0.0037\n",
      "Epoch 150/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0400 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0366 - val_mse: 0.0035\n",
      "Epoch 151/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0377 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0356 - val_mse: 0.0034\n",
      "Epoch 152/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0396 - mse: 0.0038 - val_loss: 0.0034 - val_mae: 0.0363 - val_mse: 0.0034\n",
      "Epoch 153/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0374 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0362 - val_mse: 0.0034\n",
      "Epoch 154/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0372 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0356 - val_mse: 0.0035\n",
      "Epoch 155/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0375 - mse: 0.0033 - val_loss: 0.0033 - val_mae: 0.0350 - val_mse: 0.0033\n",
      "Epoch 156/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0372 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0357 - val_mse: 0.0035\n",
      "Epoch 157/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0374 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0352 - val_mse: 0.0034\n",
      "Epoch 158/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0040 - mae: 0.0401 - mse: 0.0040 - val_loss: 0.0034 - val_mae: 0.0367 - val_mse: 0.0034\n",
      "Epoch 159/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0357 - val_mse: 0.0034\n",
      "Epoch 160/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0383 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0379 - val_mse: 0.0034\n",
      "Epoch 161/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0397 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0355 - val_mse: 0.0035\n",
      "Epoch 162/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0037 - mae: 0.0390 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0370 - val_mse: 0.0036\n",
      "Epoch 163/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0409 - mse: 0.0039 - val_loss: 0.0034 - val_mae: 0.0366 - val_mse: 0.0034\n",
      "Epoch 164/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0386 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0351 - val_mse: 0.0034\n",
      "Epoch 165/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0387 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 166/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0396 - mse: 0.0038 - val_loss: 0.0034 - val_mae: 0.0361 - val_mse: 0.0034\n",
      "Epoch 167/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0394 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0354 - val_mse: 0.0034\n",
      "Epoch 168/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0371 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0351 - val_mse: 0.0034\n",
      "Epoch 169/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0378 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0354 - val_mse: 0.0035\n",
      "Epoch 170/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0388 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0349 - val_mse: 0.0034\n",
      "Epoch 171/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0035 - val_loss: 0.0033 - val_mae: 0.0357 - val_mse: 0.0033\n",
      "Epoch 172/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0361 - val_mse: 0.0035\n",
      "Epoch 173/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0356 - val_mse: 0.0034\n",
      "Epoch 174/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0386 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0356 - val_mse: 0.0034\n",
      "Epoch 175/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0386 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0355 - val_mse: 0.0034\n",
      "Epoch 176/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0387 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0349 - val_mse: 0.0034\n",
      "Epoch 177/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0389 - mse: 0.0036 - val_loss: 0.0033 - val_mae: 0.0359 - val_mse: 0.0033\n",
      "Epoch 178/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0381 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 179/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0031 - mae: 0.0371 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0378 - val_mse: 0.0034\n",
      "Epoch 180/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0396 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 181/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0373 - mse: 0.0033 - val_loss: 0.0037 - val_mae: 0.0374 - val_mse: 0.0037\n",
      "Epoch 182/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0394 - mse: 0.0036 - val_loss: 0.0033 - val_mae: 0.0366 - val_mse: 0.0033\n",
      "Epoch 183/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0384 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0367 - val_mse: 0.0035\n",
      "Epoch 184/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0384 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0369 - val_mse: 0.0035\n",
      "Epoch 185/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0384 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0384 - val_mse: 0.0035\n",
      "Epoch 186/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0387 - mse: 0.0036 - val_loss: 0.0033 - val_mae: 0.0354 - val_mse: 0.0033\n",
      "Epoch 187/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0032 - mae: 0.0371 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0355 - val_mse: 0.0035\n",
      "Epoch 188/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0381 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0359 - val_mse: 0.0033\n",
      "Epoch 189/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0386 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0366 - val_mse: 0.0036\n",
      "Epoch 190/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0367 - mse: 0.0033 - val_loss: 0.0037 - val_mae: 0.0368 - val_mse: 0.0037\n",
      "Epoch 191/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0389 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0367 - val_mse: 0.0035\n",
      "Epoch 192/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0032 - mae: 0.0369 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0361 - val_mse: 0.0035\n",
      "Epoch 193/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0029 - mae: 0.0351 - mse: 0.0029 - val_loss: 0.0034 - val_mae: 0.0364 - val_mse: 0.0034\n",
      "Epoch 194/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0375 - mse: 0.0033 - val_loss: 0.0033 - val_mae: 0.0353 - val_mse: 0.0033\n",
      "Epoch 195/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0394 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0367 - val_mse: 0.0035\n",
      "Epoch 196/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0375 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0354 - val_mse: 0.0035\n",
      "Epoch 197/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0372 - mse: 0.0036 - val_loss: 0.0033 - val_mae: 0.0355 - val_mse: 0.0033\n",
      "Epoch 198/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0356 - val_mse: 0.0034\n",
      "Epoch 199/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0376 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0353 - val_mse: 0.0035\n",
      "Epoch 200/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0387 - mse: 0.0037 - val_loss: 0.0033 - val_mae: 0.0363 - val_mse: 0.0033\n",
      "Epoch 201/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0032 - mae: 0.0373 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0367 - val_mse: 0.0034\n",
      "Epoch 202/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0032 - mae: 0.0383 - mse: 0.0032 - val_loss: 0.0036 - val_mae: 0.0361 - val_mse: 0.0036\n",
      "Epoch 203/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0389 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0353 - val_mse: 0.0034\n",
      "Epoch 204/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0383 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0362 - val_mse: 0.0034\n",
      "Epoch 205/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0369 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0370 - val_mse: 0.0036\n",
      "Epoch 206/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0377 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0351 - val_mse: 0.0035\n",
      "Epoch 207/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0381 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0365 - val_mse: 0.0036\n",
      "Epoch 208/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0382 - mse: 0.0034 - val_loss: 0.0038 - val_mae: 0.0377 - val_mse: 0.0038\n",
      "Epoch 209/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0402 - mse: 0.0037 - val_loss: 0.0033 - val_mae: 0.0351 - val_mse: 0.0033\n",
      "Epoch 210/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0384 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 211/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0385 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0370 - val_mse: 0.0035\n",
      "Epoch 212/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0404 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0380 - val_mse: 0.0035\n",
      "Epoch 213/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0403 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0374 - val_mse: 0.0035\n",
      "Epoch 214/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0394 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0374 - val_mse: 0.0035\n",
      "Epoch 215/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0385 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0368 - val_mse: 0.0034\n",
      "Epoch 216/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0371 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0364 - val_mse: 0.0034\n",
      "Epoch 217/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0367 - val_mse: 0.0036\n",
      "Epoch 218/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0031 - mae: 0.0368 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0370 - val_mse: 0.0034\n",
      "Epoch 219/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0376 - mse: 0.0033 - val_loss: 0.0033 - val_mae: 0.0359 - val_mse: 0.0033\n",
      "Epoch 220/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0394 - mse: 0.0037 - val_loss: 0.0033 - val_mae: 0.0358 - val_mse: 0.0033\n",
      "Epoch 221/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0372 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0367 - val_mse: 0.0036\n",
      "Epoch 222/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0373 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0360 - val_mse: 0.0036\n",
      "Epoch 223/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0366 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0376 - val_mse: 0.0034\n",
      "Epoch 224/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0400 - mse: 0.0038 - val_loss: 0.0035 - val_mae: 0.0353 - val_mse: 0.0035\n",
      "Epoch 225/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0370 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0355 - val_mse: 0.0034\n",
      "Epoch 226/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0392 - mse: 0.0037 - val_loss: 0.0038 - val_mae: 0.0375 - val_mse: 0.0038\n",
      "Epoch 227/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0389 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0367 - val_mse: 0.0034\n",
      "Epoch 228/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0032 - mae: 0.0373 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0362 - val_mse: 0.0034\n",
      "Epoch 229/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0374 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0377 - val_mse: 0.0035\n",
      "Epoch 230/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0384 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0351 - val_mse: 0.0033\n",
      "Epoch 231/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0369 - mse: 0.0031 - val_loss: 0.0036 - val_mae: 0.0375 - val_mse: 0.0036\n",
      "Epoch 232/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0396 - mse: 0.0034 - val_loss: 0.0040 - val_mae: 0.0418 - val_mse: 0.0040\n",
      "Epoch 233/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0422 - mse: 0.0037 - val_loss: 0.0038 - val_mae: 0.0418 - val_mse: 0.0038\n",
      "Epoch 234/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0439 - mse: 0.0039 - val_loss: 0.0039 - val_mae: 0.0420 - val_mse: 0.0039\n",
      "Epoch 235/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0432 - mse: 0.0037 - val_loss: 0.0037 - val_mae: 0.0395 - val_mse: 0.0037\n",
      "Epoch 236/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0397 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0392 - val_mse: 0.0035\n",
      "Epoch 237/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0393 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0377 - val_mse: 0.0036\n",
      "Epoch 238/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0381 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0370 - val_mse: 0.0035\n",
      "Epoch 239/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0379 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0387 - val_mse: 0.0036\n",
      "Epoch 240/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0403 - mse: 0.0036 - val_loss: 0.0037 - val_mae: 0.0394 - val_mse: 0.0037\n",
      "Epoch 241/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0403 - mse: 0.0039 - val_loss: 0.0035 - val_mae: 0.0372 - val_mse: 0.0035\n",
      "Epoch 242/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0376 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0374 - val_mse: 0.0035\n",
      "Epoch 243/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0403 - mse: 0.0039 - val_loss: 0.0034 - val_mae: 0.0361 - val_mse: 0.0034\n",
      "Epoch 244/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0388 - mse: 0.0038 - val_loss: 0.0035 - val_mae: 0.0362 - val_mse: 0.0035\n",
      "Epoch 245/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0399 - mse: 0.0038 - val_loss: 0.0033 - val_mae: 0.0356 - val_mse: 0.0033\n",
      "Epoch 246/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0380 - mse: 0.0033 - val_loss: 0.0033 - val_mae: 0.0358 - val_mse: 0.0033\n",
      "Epoch 247/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0379 - mse: 0.0037 - val_loss: 0.0033 - val_mae: 0.0360 - val_mse: 0.0033\n",
      "Epoch 248/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0381 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0357 - val_mse: 0.0034\n",
      "Epoch 249/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0391 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0351 - val_mse: 0.0034\n",
      "Epoch 250/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0370 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0354 - val_mse: 0.0034\n",
      "Epoch 251/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0388 - mse: 0.0038 - val_loss: 0.0038 - val_mae: 0.0371 - val_mse: 0.0038\n",
      "Epoch 252/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0360 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0354 - val_mse: 0.0034\n",
      "Epoch 253/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0375 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0357 - val_mse: 0.0035\n",
      "Epoch 254/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0376 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0355 - val_mse: 0.0036\n",
      "Epoch 255/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0365 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0351 - val_mse: 0.0035\n",
      "Epoch 256/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0382 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0352 - val_mse: 0.0034\n",
      "Epoch 257/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0376 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0353 - val_mse: 0.0034\n",
      "Epoch 258/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0389 - mse: 0.0039 - val_loss: 0.0036 - val_mae: 0.0362 - val_mse: 0.0036\n",
      "Epoch 259/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0373 - mse: 0.0033 - val_loss: 0.0037 - val_mae: 0.0363 - val_mse: 0.0037\n",
      "Epoch 260/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0375 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0360 - val_mse: 0.0035\n",
      "Epoch 261/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0388 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0362 - val_mse: 0.0036\n",
      "Epoch 262/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0387 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0354 - val_mse: 0.0034\n",
      "Epoch 263/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0372 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0361 - val_mse: 0.0034\n",
      "Epoch 264/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0372 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0373 - val_mse: 0.0035\n",
      "Epoch 265/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0390 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0384 - val_mse: 0.0035\n",
      "Epoch 266/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0376 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0370 - val_mse: 0.0036\n",
      "Epoch 267/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0382 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0370 - val_mse: 0.0037\n",
      "Epoch 268/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0361 - mse: 0.0030 - val_loss: 0.0033 - val_mae: 0.0360 - val_mse: 0.0033\n",
      "Epoch 269/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0396 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0359 - val_mse: 0.0035\n",
      "Epoch 270/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0373 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 271/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0371 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0356 - val_mse: 0.0034\n",
      "Epoch 272/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0371 - mse: 0.0033 - val_loss: 0.0038 - val_mae: 0.0367 - val_mse: 0.0038\n",
      "Epoch 273/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0385 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0357 - val_mse: 0.0034\n",
      "Epoch 274/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0371 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0372 - val_mse: 0.0035\n",
      "Epoch 275/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0381 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0364 - val_mse: 0.0034\n",
      "Epoch 276/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0365 - mse: 0.0030 - val_loss: 0.0036 - val_mae: 0.0372 - val_mse: 0.0036\n",
      "Epoch 277/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0376 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0382 - val_mse: 0.0036\n",
      "Epoch 278/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0389 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0374 - val_mse: 0.0036\n",
      "Epoch 279/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0387 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0384 - val_mse: 0.0035\n",
      "Epoch 280/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0387 - mse: 0.0033 - val_loss: 0.0037 - val_mae: 0.0395 - val_mse: 0.0037\n",
      "Epoch 281/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0431 - mse: 0.0039 - val_loss: 0.0040 - val_mae: 0.0408 - val_mse: 0.0040\n",
      "Epoch 282/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0395 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0376 - val_mse: 0.0035\n",
      "Epoch 283/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0385 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0371 - val_mse: 0.0036\n",
      "Epoch 284/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0407 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0373 - val_mse: 0.0036\n",
      "Epoch 285/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0389 - mse: 0.0035 - val_loss: 0.0037 - val_mae: 0.0380 - val_mse: 0.0037\n",
      "Epoch 286/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0395 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0365 - val_mse: 0.0036\n",
      "Epoch 287/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0377 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0374 - val_mse: 0.0035\n",
      "Epoch 288/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0404 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 289/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0400 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0364 - val_mse: 0.0035\n",
      "Epoch 290/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0360 - val_mse: 0.0035\n",
      "Epoch 291/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0376 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0367 - val_mse: 0.0035\n",
      "Epoch 292/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0381 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0351 - val_mse: 0.0034\n",
      "Epoch 293/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0389 - mse: 0.0038 - val_loss: 0.0035 - val_mae: 0.0351 - val_mse: 0.0035\n",
      "Epoch 294/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0367 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0359 - val_mse: 0.0035\n",
      "Epoch 295/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0373 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0363 - val_mse: 0.0035\n",
      "Epoch 296/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0386 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0350 - val_mse: 0.0035\n",
      "Epoch 297/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0358 - mse: 0.0030 - val_loss: 0.0033 - val_mae: 0.0348 - val_mse: 0.0033\n",
      "Epoch 298/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0371 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0357 - val_mse: 0.0035\n",
      "Epoch 299/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0386 - mse: 0.0038 - val_loss: 0.0034 - val_mae: 0.0353 - val_mse: 0.0034\n",
      "Epoch 300/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0363 - mse: 0.0031 - val_loss: 0.0035 - val_mae: 0.0359 - val_mse: 0.0035\n",
      "Epoch 301/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0380 - mse: 0.0034 - val_loss: 0.0040 - val_mae: 0.0374 - val_mse: 0.0040\n",
      "Epoch 302/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0388 - mse: 0.0039 - val_loss: 0.0035 - val_mae: 0.0370 - val_mse: 0.0035\n",
      "Epoch 303/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0393 - mse: 0.0039 - val_loss: 0.0035 - val_mae: 0.0376 - val_mse: 0.0035\n",
      "Epoch 304/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0035 - val_loss: 0.0033 - val_mae: 0.0358 - val_mse: 0.0033\n",
      "Epoch 305/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0389 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0358 - val_mse: 0.0034\n",
      "Epoch 306/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0392 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0351 - val_mse: 0.0034\n",
      "Epoch 307/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0386 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0350 - val_mse: 0.0034\n",
      "Epoch 308/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0382 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0355 - val_mse: 0.0033\n",
      "Epoch 309/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0379 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0364 - val_mse: 0.0037\n",
      "Epoch 310/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0379 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 311/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0356 - mse: 0.0032 - val_loss: 0.0036 - val_mae: 0.0379 - val_mse: 0.0036\n",
      "Epoch 312/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0378 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0352 - val_mse: 0.0033\n",
      "Epoch 313/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0375 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0353 - val_mse: 0.0034\n",
      "Epoch 314/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0369 - mse: 0.0033 - val_loss: 0.0033 - val_mae: 0.0350 - val_mse: 0.0033\n",
      "Epoch 315/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0358 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0355 - val_mse: 0.0035\n",
      "Epoch 316/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0373 - val_mse: 0.0036\n",
      "Epoch 317/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0387 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0367 - val_mse: 0.0035\n",
      "Epoch 318/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0378 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0386 - val_mse: 0.0036\n",
      "Epoch 319/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0384 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0383 - val_mse: 0.0036\n",
      "Epoch 320/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0394 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0376 - val_mse: 0.0035\n",
      "Epoch 321/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0404 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0358 - val_mse: 0.0034\n",
      "Epoch 322/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0386 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0363 - val_mse: 0.0035\n",
      "Epoch 323/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0371 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0361 - val_mse: 0.0036\n",
      "Epoch 324/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0368 - mse: 0.0035 - val_loss: 0.0033 - val_mae: 0.0351 - val_mse: 0.0033\n",
      "Epoch 325/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0364 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 326/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0374 - mse: 0.0031 - val_loss: 0.0035 - val_mae: 0.0363 - val_mse: 0.0035\n",
      "Epoch 327/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0378 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0378 - val_mse: 0.0036\n",
      "Epoch 328/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0040 - mae: 0.0405 - mse: 0.0040 - val_loss: 0.0033 - val_mae: 0.0360 - val_mse: 0.0033\n",
      "Epoch 329/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0384 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0356 - val_mse: 0.0033\n",
      "Epoch 330/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0389 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0350 - val_mse: 0.0034\n",
      "Epoch 331/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0377 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0358 - val_mse: 0.0034\n",
      "Epoch 332/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0386 - mse: 0.0038 - val_loss: 0.0034 - val_mae: 0.0361 - val_mse: 0.0034\n",
      "Epoch 333/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0363 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0359 - val_mse: 0.0035\n",
      "Epoch 334/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0371 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 335/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0380 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0355 - val_mse: 0.0034\n",
      "Epoch 336/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0370 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0353 - val_mse: 0.0034\n",
      "Epoch 337/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0375 - mse: 0.0035 - val_loss: 0.0033 - val_mae: 0.0350 - val_mse: 0.0033\n",
      "Epoch 338/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0369 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0364 - val_mse: 0.0036\n",
      "Epoch 339/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0382 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0351 - val_mse: 0.0035\n",
      "Epoch 340/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0379 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0355 - val_mse: 0.0034\n",
      "Epoch 341/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0375 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0354 - val_mse: 0.0035\n",
      "Epoch 342/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0394 - mse: 0.0038 - val_loss: 0.0033 - val_mae: 0.0344 - val_mse: 0.0033\n",
      "Epoch 343/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0373 - mse: 0.0035 - val_loss: 0.0033 - val_mae: 0.0351 - val_mse: 0.0033\n",
      "Epoch 344/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0367 - mse: 0.0032 - val_loss: 0.0033 - val_mae: 0.0350 - val_mse: 0.0033\n",
      "Epoch 345/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0370 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0372 - val_mse: 0.0035\n",
      "Epoch 346/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0396 - mse: 0.0039 - val_loss: 0.0034 - val_mae: 0.0348 - val_mse: 0.0034\n",
      "Epoch 347/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0378 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0355 - val_mse: 0.0034\n",
      "Epoch 348/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0358 - mse: 0.0030 - val_loss: 0.0033 - val_mae: 0.0360 - val_mse: 0.0033\n",
      "Epoch 349/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0357 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0347 - val_mse: 0.0034\n",
      "Epoch 350/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0365 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 351/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0373 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0350 - val_mse: 0.0034\n",
      "Epoch 352/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0351 - mse: 0.0030 - val_loss: 0.0034 - val_mae: 0.0349 - val_mse: 0.0034\n",
      "Epoch 353/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0375 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0353 - val_mse: 0.0035\n",
      "Epoch 354/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0369 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0352 - val_mse: 0.0035\n",
      "Epoch 355/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0364 - mse: 0.0032 - val_loss: 0.0033 - val_mae: 0.0366 - val_mse: 0.0033\n",
      "Epoch 356/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0388 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0353 - val_mse: 0.0034\n",
      "Epoch 357/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0359 - mse: 0.0031 - val_loss: 0.0036 - val_mae: 0.0354 - val_mse: 0.0036\n",
      "Epoch 358/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0355 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0361 - val_mse: 0.0034\n",
      "Epoch 359/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0376 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0356 - val_mse: 0.0035\n",
      "Epoch 360/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0373 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0356 - val_mse: 0.0034\n",
      "Epoch 361/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0374 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0358 - val_mse: 0.0035\n",
      "Epoch 362/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0387 - val_mse: 0.0036\n",
      "Epoch 363/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0383 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0362 - val_mse: 0.0035\n",
      "Epoch 364/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0384 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0369 - val_mse: 0.0034\n",
      "Epoch 365/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0386 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0356 - val_mse: 0.0034\n",
      "Epoch 366/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0379 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0370 - val_mse: 0.0036\n",
      "Epoch 367/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0385 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0354 - val_mse: 0.0034\n",
      "Epoch 368/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0377 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0363 - val_mse: 0.0034\n",
      "Epoch 369/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0371 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0364 - val_mse: 0.0034\n",
      "Epoch 370/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0367 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0357 - val_mse: 0.0034\n",
      "Epoch 371/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0378 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0365 - val_mse: 0.0033\n",
      "Epoch 372/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0371 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 373/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0368 - mse: 0.0033 - val_loss: 0.0033 - val_mae: 0.0354 - val_mse: 0.0033\n",
      "Epoch 374/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0376 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0350 - val_mse: 0.0034\n",
      "Epoch 375/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0362 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0354 - val_mse: 0.0034\n",
      "Epoch 376/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0407 - mse: 0.0039 - val_loss: 0.0038 - val_mae: 0.0375 - val_mse: 0.0038\n",
      "Epoch 377/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0381 - mse: 0.0034 - val_loss: 0.0038 - val_mae: 0.0400 - val_mse: 0.0038\n",
      "Epoch 378/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0412 - mse: 0.0038 - val_loss: 0.0041 - val_mae: 0.0406 - val_mse: 0.0041\n",
      "Epoch 379/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0406 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0373 - val_mse: 0.0034\n",
      "Epoch 380/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0394 - mse: 0.0035 - val_loss: 0.0039 - val_mae: 0.0421 - val_mse: 0.0039\n",
      "Epoch 381/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0416 - mse: 0.0036 - val_loss: 0.0037 - val_mae: 0.0401 - val_mse: 0.0037\n",
      "Epoch 382/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0402 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0386 - val_mse: 0.0036\n",
      "Epoch 383/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0401 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0387 - val_mse: 0.0034\n",
      "Epoch 384/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0387 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0371 - val_mse: 0.0036\n",
      "Epoch 385/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0383 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0363 - val_mse: 0.0034\n",
      "Epoch 386/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0382 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0364 - val_mse: 0.0035\n",
      "Epoch 387/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0378 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0367 - val_mse: 0.0037\n",
      "Epoch 388/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0389 - mse: 0.0036 - val_loss: 0.0033 - val_mae: 0.0352 - val_mse: 0.0033\n",
      "Epoch 389/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0367 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0358 - val_mse: 0.0035\n",
      "Epoch 390/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0376 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0359 - val_mse: 0.0034\n",
      "Epoch 391/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0380 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0356 - val_mse: 0.0035\n",
      "Epoch 392/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0377 - mse: 0.0038 - val_loss: 0.0035 - val_mae: 0.0359 - val_mse: 0.0035\n",
      "Epoch 393/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0395 - mse: 0.0038 - val_loss: 0.0033 - val_mae: 0.0354 - val_mse: 0.0033\n",
      "Epoch 394/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0373 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0357 - val_mse: 0.0034\n",
      "Epoch 395/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0397 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0351 - val_mse: 0.0034\n",
      "Epoch 396/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0370 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0371 - val_mse: 0.0034\n",
      "Epoch 397/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0398 - mse: 0.0038 - val_loss: 0.0033 - val_mae: 0.0358 - val_mse: 0.0033\n",
      "Epoch 398/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0374 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0347 - val_mse: 0.0033\n",
      "Epoch 399/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0368 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0353 - val_mse: 0.0035\n",
      "Epoch 400/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0359 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0358 - val_mse: 0.0035\n",
      "Epoch 401/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0361 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0369 - val_mse: 0.0034\n",
      "Epoch 402/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0376 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0353 - val_mse: 0.0034\n",
      "Epoch 403/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0366 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 404/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0380 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0360 - val_mse: 0.0035\n",
      "Epoch 405/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0361 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0361 - val_mse: 0.0035\n",
      "Epoch 406/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0374 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0362 - val_mse: 0.0035\n",
      "Epoch 407/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0372 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0359 - val_mse: 0.0035\n",
      "Epoch 408/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0384 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0358 - val_mse: 0.0034\n",
      "Epoch 409/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0368 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0363 - val_mse: 0.0035\n",
      "Epoch 410/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0379 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0357 - val_mse: 0.0034\n",
      "Epoch 411/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0380 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0371 - val_mse: 0.0035\n",
      "Epoch 412/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0372 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0369 - val_mse: 0.0035\n",
      "Epoch 413/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0373 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0364 - val_mse: 0.0035\n",
      "Epoch 414/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0369 - mse: 0.0032 - val_loss: 0.0037 - val_mae: 0.0390 - val_mse: 0.0037\n",
      "Epoch 415/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0378 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0373 - val_mse: 0.0035\n",
      "Epoch 416/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0372 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0365 - val_mse: 0.0035\n",
      "Epoch 417/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0371 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0359 - val_mse: 0.0034\n",
      "Epoch 418/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0377 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0364 - val_mse: 0.0034\n",
      "Epoch 419/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0373 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0359 - val_mse: 0.0034\n",
      "Epoch 420/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0376 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0356 - val_mse: 0.0034\n",
      "Epoch 421/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0374 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 422/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0361 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0356 - val_mse: 0.0035\n",
      "Epoch 423/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0380 - mse: 0.0039 - val_loss: 0.0035 - val_mae: 0.0360 - val_mse: 0.0035\n",
      "Epoch 424/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0375 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0356 - val_mse: 0.0034\n",
      "Epoch 425/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0371 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0363 - val_mse: 0.0034\n",
      "Epoch 426/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0374 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0353 - val_mse: 0.0034\n",
      "Epoch 427/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0355 - mse: 0.0032 - val_loss: 0.0033 - val_mae: 0.0351 - val_mse: 0.0033\n",
      "Epoch 428/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0366 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0356 - val_mse: 0.0035\n",
      "Epoch 429/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0365 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0371 - val_mse: 0.0035\n",
      "Epoch 430/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0372 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0376 - val_mse: 0.0035\n",
      "Epoch 431/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0387 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0374 - val_mse: 0.0035\n",
      "Epoch 432/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0373 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0367 - val_mse: 0.0036\n",
      "Epoch 433/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0371 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0358 - val_mse: 0.0035\n",
      "Epoch 434/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0364 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0373 - val_mse: 0.0036\n",
      "Epoch 435/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0376 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0367 - val_mse: 0.0036\n",
      "Epoch 436/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0365 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0358 - val_mse: 0.0034\n",
      "Epoch 437/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0383 - mse: 0.0038 - val_loss: 0.0035 - val_mae: 0.0362 - val_mse: 0.0035\n",
      "Epoch 438/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0375 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0376 - val_mse: 0.0036\n",
      "Epoch 439/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0378 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0372 - val_mse: 0.0035\n",
      "Epoch 440/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0388 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0358 - val_mse: 0.0035\n",
      "Epoch 441/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0380 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0360 - val_mse: 0.0035\n",
      "Epoch 442/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0357 - mse: 0.0031 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 443/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0379 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0380 - val_mse: 0.0035\n",
      "Epoch 444/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0381 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 445/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0367 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0375 - val_mse: 0.0035\n",
      "Epoch 446/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0383 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0384 - val_mse: 0.0036\n",
      "Epoch 447/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0377 - mse: 0.0032 - val_loss: 0.0037 - val_mae: 0.0382 - val_mse: 0.0037\n",
      "Epoch 448/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0380 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0371 - val_mse: 0.0036\n",
      "Epoch 449/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0376 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0373 - val_mse: 0.0036\n",
      "Epoch 450/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0376 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0374 - val_mse: 0.0035\n",
      "Epoch 451/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0369 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0362 - val_mse: 0.0034\n",
      "Epoch 452/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0376 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0370 - val_mse: 0.0035\n",
      "Epoch 453/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0370 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 454/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0361 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0370 - val_mse: 0.0034\n",
      "Epoch 455/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0369 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0366 - val_mse: 0.0035\n",
      "Epoch 456/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0361 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0374 - val_mse: 0.0035\n",
      "Epoch 457/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0364 - mse: 0.0031 - val_loss: 0.0035 - val_mae: 0.0366 - val_mse: 0.0035\n",
      "Epoch 458/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0376 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0364 - val_mse: 0.0035\n",
      "Epoch 459/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0374 - mse: 0.0033 - val_loss: 0.0037 - val_mae: 0.0374 - val_mse: 0.0037\n",
      "Epoch 460/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0379 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0376 - val_mse: 0.0035\n",
      "Epoch 461/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0357 - mse: 0.0030 - val_loss: 0.0034 - val_mae: 0.0371 - val_mse: 0.0034\n",
      "Epoch 462/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0370 - mse: 0.0032 - val_loss: 0.0037 - val_mae: 0.0381 - val_mse: 0.0037\n",
      "Epoch 463/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0381 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0380 - val_mse: 0.0035\n",
      "Epoch 464/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0366 - mse: 0.0030 - val_loss: 0.0039 - val_mae: 0.0392 - val_mse: 0.0039\n",
      "Epoch 465/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0393 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0403 - val_mse: 0.0037\n",
      "Epoch 466/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0394 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0374 - val_mse: 0.0036\n",
      "Epoch 467/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0389 - mse: 0.0035 - val_loss: 0.0033 - val_mae: 0.0367 - val_mse: 0.0033\n",
      "Epoch 468/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0359 - mse: 0.0030 - val_loss: 0.0033 - val_mae: 0.0354 - val_mse: 0.0033\n",
      "Epoch 469/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0370 - mse: 0.0032 - val_loss: 0.0036 - val_mae: 0.0366 - val_mse: 0.0036\n",
      "Epoch 470/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0389 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0371 - val_mse: 0.0034\n",
      "Epoch 471/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0373 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0378 - val_mse: 0.0035\n",
      "Epoch 472/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0389 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0382 - val_mse: 0.0035\n",
      "Epoch 473/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0383 - mse: 0.0031 - val_loss: 0.0037 - val_mae: 0.0398 - val_mse: 0.0037\n",
      "Epoch 474/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0395 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0367 - val_mse: 0.0035\n",
      "Epoch 475/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0383 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0369 - val_mse: 0.0036\n",
      "Epoch 476/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0368 - mse: 0.0033 - val_loss: 0.0033 - val_mae: 0.0365 - val_mse: 0.0033\n",
      "Epoch 477/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0379 - mse: 0.0035 - val_loss: 0.0033 - val_mae: 0.0352 - val_mse: 0.0033\n",
      "Epoch 478/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0378 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0353 - val_mse: 0.0033\n",
      "Epoch 479/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0360 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0364 - val_mse: 0.0034\n",
      "Epoch 480/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0364 - mse: 0.0031 - val_loss: 0.0035 - val_mae: 0.0366 - val_mse: 0.0035\n",
      "Epoch 481/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0366 - mse: 0.0031 - val_loss: 0.0035 - val_mae: 0.0373 - val_mse: 0.0035\n",
      "Epoch 482/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0381 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0370 - val_mse: 0.0036\n",
      "Epoch 483/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0374 - mse: 0.0033 - val_loss: 0.0037 - val_mae: 0.0375 - val_mse: 0.0037\n",
      "Epoch 484/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0386 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0386 - val_mse: 0.0037\n",
      "Epoch 485/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0385 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0370 - val_mse: 0.0035\n",
      "Epoch 486/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0388 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0375 - val_mse: 0.0035\n",
      "Epoch 487/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0398 - mse: 0.0038 - val_loss: 0.0035 - val_mae: 0.0374 - val_mse: 0.0035\n",
      "Epoch 488/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0389 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0368 - val_mse: 0.0034\n",
      "Epoch 489/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0396 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0362 - val_mse: 0.0035\n",
      "Epoch 490/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0381 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0365 - val_mse: 0.0034\n",
      "Epoch 491/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0387 - mse: 0.0036 - val_loss: 0.0033 - val_mae: 0.0370 - val_mse: 0.0033\n",
      "Epoch 492/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0392 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0368 - val_mse: 0.0036\n",
      "Epoch 493/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0385 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0371 - val_mse: 0.0035\n",
      "Epoch 494/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0396 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0364 - val_mse: 0.0036\n",
      "Epoch 495/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0389 - mse: 0.0037 - val_loss: 0.0040 - val_mae: 0.0390 - val_mse: 0.0040\n",
      "Epoch 496/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0408 - mse: 0.0036 - val_loss: 0.0037 - val_mae: 0.0376 - val_mse: 0.0037\n",
      "Epoch 497/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0409 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0382 - val_mse: 0.0036\n",
      "Epoch 498/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0424 - mse: 0.0039 - val_loss: 0.0036 - val_mae: 0.0372 - val_mse: 0.0036\n",
      "Epoch 499/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0395 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0366 - val_mse: 0.0036\n",
      "Epoch 500/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0375 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0358 - val_mse: 0.0035\n",
      "Epoch 501/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0383 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0357 - val_mse: 0.0034\n",
      "Epoch 502/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0381 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0362 - val_mse: 0.0034\n",
      "Epoch 503/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0359 - mse: 0.0030 - val_loss: 0.0035 - val_mae: 0.0362 - val_mse: 0.0035\n",
      "Epoch 504/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0381 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0367 - val_mse: 0.0036\n",
      "Epoch 505/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0388 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0367 - val_mse: 0.0036\n",
      "Epoch 506/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0388 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0384 - val_mse: 0.0036\n",
      "Epoch 507/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0384 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0368 - val_mse: 0.0036\n",
      "Epoch 508/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0373 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 509/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0375 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0362 - val_mse: 0.0035\n",
      "Epoch 510/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0360 - mse: 0.0030 - val_loss: 0.0034 - val_mae: 0.0376 - val_mse: 0.0034\n",
      "Epoch 511/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0382 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0367 - val_mse: 0.0034\n",
      "Epoch 512/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0388 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0361 - val_mse: 0.0035\n",
      "Epoch 513/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0381 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0373 - val_mse: 0.0037\n",
      "Epoch 514/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0392 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0372 - val_mse: 0.0035\n",
      "Epoch 515/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0373 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0367 - val_mse: 0.0036\n",
      "Epoch 516/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0387 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0370 - val_mse: 0.0035\n",
      "Epoch 517/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0380 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0367 - val_mse: 0.0034\n",
      "Epoch 518/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0390 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0356 - val_mse: 0.0035\n",
      "Epoch 519/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0375 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0361 - val_mse: 0.0036\n",
      "Epoch 520/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0386 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0360 - val_mse: 0.0035\n",
      "Epoch 521/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0382 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0357 - val_mse: 0.0035\n",
      "Epoch 522/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0366 - mse: 0.0031 - val_loss: 0.0036 - val_mae: 0.0376 - val_mse: 0.0036\n",
      "Epoch 523/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0379 - mse: 0.0032 - val_loss: 0.0037 - val_mae: 0.0376 - val_mse: 0.0037\n",
      "Epoch 524/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0382 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0374 - val_mse: 0.0036\n",
      "Epoch 525/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0400 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0369 - val_mse: 0.0036\n",
      "Epoch 526/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0399 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0372 - val_mse: 0.0036\n",
      "Epoch 527/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0369 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0360 - val_mse: 0.0035\n",
      "Epoch 528/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0385 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0354 - val_mse: 0.0034\n",
      "Epoch 529/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0370 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0351 - val_mse: 0.0034\n",
      "Epoch 530/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0363 - mse: 0.0032 - val_loss: 0.0036 - val_mae: 0.0357 - val_mse: 0.0036\n",
      "Epoch 531/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0375 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0356 - val_mse: 0.0034\n",
      "Epoch 532/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0379 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 533/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0363 - mse: 0.0032 - val_loss: 0.0036 - val_mae: 0.0382 - val_mse: 0.0036\n",
      "Epoch 534/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0359 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0359 - val_mse: 0.0035\n",
      "Epoch 535/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0372 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0360 - val_mse: 0.0035\n",
      "Epoch 536/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0375 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0359 - val_mse: 0.0035\n",
      "Epoch 537/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0366 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0369 - val_mse: 0.0036\n",
      "Epoch 538/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0364 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 539/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0366 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0355 - val_mse: 0.0034\n",
      "Epoch 540/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0369 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0364 - val_mse: 0.0035\n",
      "Epoch 541/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0362 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0366 - val_mse: 0.0036\n",
      "Epoch 542/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0378 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0367 - val_mse: 0.0036\n",
      "Epoch 543/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0386 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0368 - val_mse: 0.0036\n",
      "Epoch 544/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0366 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0364 - val_mse: 0.0035\n",
      "Epoch 545/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0379 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0361 - val_mse: 0.0036\n",
      "Epoch 546/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0356 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0351 - val_mse: 0.0034\n",
      "Epoch 547/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0370 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0358 - val_mse: 0.0035\n",
      "Epoch 548/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0355 - mse: 0.0031 - val_loss: 0.0036 - val_mae: 0.0365 - val_mse: 0.0036\n",
      "Epoch 549/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0386 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0358 - val_mse: 0.0034\n",
      "Epoch 550/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0349 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 551/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0375 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0356 - val_mse: 0.0035\n",
      "Epoch 552/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0361 - mse: 0.0032 - val_loss: 0.0036 - val_mae: 0.0379 - val_mse: 0.0036\n",
      "Epoch 553/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0385 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0354 - val_mse: 0.0035\n",
      "Epoch 554/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0360 - mse: 0.0032 - val_loss: 0.0033 - val_mae: 0.0363 - val_mse: 0.0033\n",
      "Epoch 555/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0375 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0353 - val_mse: 0.0034\n",
      "Epoch 556/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0357 - mse: 0.0030 - val_loss: 0.0036 - val_mae: 0.0363 - val_mse: 0.0036\n",
      "Epoch 557/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0402 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0360 - val_mse: 0.0035\n",
      "Epoch 558/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0376 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0358 - val_mse: 0.0035\n",
      "Epoch 559/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0366 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0375 - val_mse: 0.0035\n",
      "Epoch 560/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0382 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0363 - val_mse: 0.0035\n",
      "Epoch 561/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0372 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0358 - val_mse: 0.0035\n",
      "Epoch 562/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0360 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0356 - val_mse: 0.0035\n",
      "Epoch 563/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0369 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0352 - val_mse: 0.0034\n",
      "Epoch 564/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0376 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0364 - val_mse: 0.0035\n",
      "Epoch 565/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0367 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0358 - val_mse: 0.0035\n",
      "Epoch 566/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0377 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0357 - val_mse: 0.0035\n",
      "Epoch 567/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0347 - mse: 0.0028 - val_loss: 0.0035 - val_mae: 0.0359 - val_mse: 0.0035\n",
      "Epoch 568/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0367 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0358 - val_mse: 0.0035\n",
      "Epoch 569/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0363 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 570/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0367 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0364 - val_mse: 0.0035\n",
      "Epoch 571/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0381 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0368 - val_mse: 0.0034\n",
      "Epoch 572/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0382 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0363 - val_mse: 0.0035\n",
      "Epoch 573/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0395 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0361 - val_mse: 0.0035\n",
      "Epoch 574/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0372 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0356 - val_mse: 0.0035\n",
      "Epoch 575/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0363 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0353 - val_mse: 0.0035\n",
      "Epoch 576/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0356 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0352 - val_mse: 0.0034\n",
      "Epoch 577/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0370 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0344 - val_mse: 0.0033\n",
      "Epoch 578/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0355 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0358 - val_mse: 0.0034\n",
      "Epoch 579/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0371 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0350 - val_mse: 0.0034\n",
      "Epoch 580/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0369 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0366 - val_mse: 0.0035\n",
      "Epoch 581/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0033 - mae: 0.0365 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0350 - val_mse: 0.0035\n",
      "Epoch 582/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0373 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0351 - val_mse: 0.0034\n",
      "Epoch 583/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0371 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0353 - val_mse: 0.0035\n",
      "Epoch 584/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0362 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0365 - val_mse: 0.0035\n",
      "Epoch 585/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0390 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0370 - val_mse: 0.0036\n",
      "Epoch 586/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0366 - mse: 0.0030 - val_loss: 0.0036 - val_mae: 0.0367 - val_mse: 0.0036\n",
      "Epoch 587/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0367 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0358 - val_mse: 0.0034\n",
      "Epoch 588/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0371 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0368 - val_mse: 0.0036\n",
      "Epoch 589/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0384 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0365 - val_mse: 0.0034\n",
      "Epoch 590/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0375 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0369 - val_mse: 0.0034\n",
      "Epoch 591/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0361 - mse: 0.0030 - val_loss: 0.0034 - val_mae: 0.0353 - val_mse: 0.0034\n",
      "Epoch 592/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0381 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0362 - val_mse: 0.0035\n",
      "Epoch 593/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0376 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0354 - val_mse: 0.0034\n",
      "Epoch 594/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0372 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0353 - val_mse: 0.0035\n",
      "Epoch 595/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0360 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0350 - val_mse: 0.0034\n",
      "Epoch 596/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0352 - mse: 0.0030 - val_loss: 0.0036 - val_mae: 0.0353 - val_mse: 0.0036\n",
      "Epoch 597/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0366 - mse: 0.0033 - val_loss: 0.0037 - val_mae: 0.0369 - val_mse: 0.0037\n",
      "Epoch 598/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0370 - mse: 0.0032 - val_loss: 0.0040 - val_mae: 0.0403 - val_mse: 0.0040\n",
      "Epoch 599/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0419 - mse: 0.0038 - val_loss: 0.0038 - val_mae: 0.0394 - val_mse: 0.0038\n",
      "Epoch 600/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0391 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0357 - val_mse: 0.0035\n",
      "Epoch 601/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0390 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0354 - val_mse: 0.0035\n",
      "Epoch 602/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0372 - mse: 0.0031 - val_loss: 0.0036 - val_mae: 0.0362 - val_mse: 0.0036\n",
      "Epoch 603/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0373 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0355 - val_mse: 0.0034\n",
      "Epoch 604/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0371 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0357 - val_mse: 0.0037\n",
      "Epoch 605/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0357 - mse: 0.0029 - val_loss: 0.0035 - val_mae: 0.0360 - val_mse: 0.0035\n",
      "Epoch 606/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0383 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0353 - val_mse: 0.0035\n",
      "Epoch 607/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0365 - mse: 0.0031 - val_loss: 0.0035 - val_mae: 0.0351 - val_mse: 0.0035\n",
      "Epoch 608/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0369 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0352 - val_mse: 0.0035\n",
      "Epoch 609/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - mae: 0.0365 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0355 - val_mse: 0.0035\n",
      "Epoch 610/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0370 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0353 - val_mse: 0.0034\n",
      "Epoch 611/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0380 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0365 - val_mse: 0.0036\n",
      "Epoch 612/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0362 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0365 - val_mse: 0.0034\n",
      "Epoch 613/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0379 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0365 - val_mse: 0.0035\n",
      "Epoch 614/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0386 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0357 - val_mse: 0.0035\n",
      "Epoch 615/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0386 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0366 - val_mse: 0.0036\n",
      "Epoch 616/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0397 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0374 - val_mse: 0.0036\n",
      "Epoch 617/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0388 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0367 - val_mse: 0.0036\n",
      "Epoch 618/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0383 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0365 - val_mse: 0.0036\n",
      "Epoch 619/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0377 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0367 - val_mse: 0.0035\n",
      "Epoch 620/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0391 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0362 - val_mse: 0.0035\n",
      "Epoch 621/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0371 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0357 - val_mse: 0.0035\n",
      "Epoch 622/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0380 - mse: 0.0033 - val_loss: 0.0037 - val_mae: 0.0367 - val_mse: 0.0037\n",
      "Epoch 623/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0363 - mse: 0.0032 - val_loss: 0.0036 - val_mae: 0.0360 - val_mse: 0.0036\n",
      "Epoch 624/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0365 - mse: 0.0032 - val_loss: 0.0037 - val_mae: 0.0364 - val_mse: 0.0037\n",
      "Epoch 625/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0362 - mse: 0.0031 - val_loss: 0.0035 - val_mae: 0.0363 - val_mse: 0.0035\n",
      "Epoch 626/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0380 - mse: 0.0033 - val_loss: 0.0038 - val_mae: 0.0386 - val_mse: 0.0038\n",
      "Epoch 627/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0388 - mse: 0.0035 - val_loss: 0.0037 - val_mae: 0.0388 - val_mse: 0.0037\n",
      "Epoch 628/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0409 - mse: 0.0037 - val_loss: 0.0037 - val_mae: 0.0383 - val_mse: 0.0037\n",
      "Epoch 629/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0390 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0377 - val_mse: 0.0035\n",
      "Epoch 630/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0391 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0374 - val_mse: 0.0035\n",
      "Epoch 631/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0383 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0371 - val_mse: 0.0035\n",
      "Epoch 632/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0388 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0374 - val_mse: 0.0035\n",
      "Epoch 633/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0382 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0375 - val_mse: 0.0037\n",
      "Epoch 634/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0381 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0369 - val_mse: 0.0034\n",
      "Epoch 635/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0380 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0384 - val_mse: 0.0035\n",
      "Epoch 636/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0405 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0377 - val_mse: 0.0036\n",
      "Epoch 637/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0380 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0368 - val_mse: 0.0034\n",
      "Epoch 638/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0386 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0390 - val_mse: 0.0036\n",
      "Epoch 639/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0385 - mse: 0.0032 - val_loss: 0.0037 - val_mae: 0.0398 - val_mse: 0.0037\n",
      "Epoch 640/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0406 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0385 - val_mse: 0.0037\n",
      "Epoch 641/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0397 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0385 - val_mse: 0.0035\n",
      "Epoch 642/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0391 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0373 - val_mse: 0.0035\n",
      "Epoch 643/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0392 - mse: 0.0035 - val_loss: 0.0037 - val_mae: 0.0377 - val_mse: 0.0037\n",
      "Epoch 644/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0387 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0373 - val_mse: 0.0035\n",
      "Epoch 645/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0385 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0371 - val_mse: 0.0035\n",
      "Epoch 646/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0385 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0371 - val_mse: 0.0034\n",
      "Epoch 647/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0380 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0373 - val_mse: 0.0035\n",
      "Epoch 648/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0387 - mse: 0.0034 - val_loss: 0.0038 - val_mae: 0.0425 - val_mse: 0.0038\n",
      "Epoch 649/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0428 - mse: 0.0037 - val_loss: 0.0038 - val_mae: 0.0423 - val_mse: 0.0038\n",
      "Epoch 650/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0038 - mae: 0.0438 - mse: 0.0038 - val_loss: 0.0036 - val_mae: 0.0374 - val_mse: 0.0036\n",
      "Epoch 651/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0033 - mae: 0.0388 - mse: 0.0033 - val_loss: 0.0037 - val_mae: 0.0406 - val_mse: 0.0037\n",
      "Epoch 652/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0037 - mae: 0.0418 - mse: 0.0037 - val_loss: 0.0038 - val_mae: 0.0416 - val_mse: 0.0038\n",
      "Epoch 653/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0421 - mse: 0.0038 - val_loss: 0.0037 - val_mae: 0.0404 - val_mse: 0.0037\n",
      "Epoch 654/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0398 - mse: 0.0033 - val_loss: 0.0037 - val_mae: 0.0378 - val_mse: 0.0037\n",
      "Epoch 655/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0383 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0379 - val_mse: 0.0035\n",
      "Epoch 656/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0394 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0376 - val_mse: 0.0035\n",
      "Epoch 657/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0388 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0374 - val_mse: 0.0035\n",
      "Epoch 658/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0399 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0380 - val_mse: 0.0036\n",
      "Epoch 659/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0394 - mse: 0.0034 - val_loss: 0.0038 - val_mae: 0.0384 - val_mse: 0.0038\n",
      "Epoch 660/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0402 - mse: 0.0034 - val_loss: 0.0039 - val_mae: 0.0419 - val_mse: 0.0039\n",
      "Epoch 661/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0411 - mse: 0.0035 - val_loss: 0.0037 - val_mae: 0.0401 - val_mse: 0.0037\n",
      "Epoch 662/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0404 - mse: 0.0033 - val_loss: 0.0039 - val_mae: 0.0401 - val_mse: 0.0039\n",
      "Epoch 663/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0402 - mse: 0.0035 - val_loss: 0.0039 - val_mae: 0.0410 - val_mse: 0.0039\n",
      "Epoch 664/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0039 - mae: 0.0435 - mse: 0.0039 - val_loss: 0.0038 - val_mae: 0.0404 - val_mse: 0.0038\n",
      "Epoch 665/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0038 - mae: 0.0434 - mse: 0.0038 - val_loss: 0.0041 - val_mae: 0.0431 - val_mse: 0.0041\n",
      "Epoch 666/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0039 - mae: 0.0439 - mse: 0.0039 - val_loss: 0.0038 - val_mae: 0.0404 - val_mse: 0.0038\n",
      "Epoch 667/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0403 - mse: 0.0034 - val_loss: 0.0038 - val_mae: 0.0389 - val_mse: 0.0038\n",
      "Epoch 668/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0392 - mse: 0.0032 - val_loss: 0.0037 - val_mae: 0.0395 - val_mse: 0.0037\n",
      "Epoch 669/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0039 - mae: 0.0416 - mse: 0.0039 - val_loss: 0.0037 - val_mae: 0.0404 - val_mse: 0.0037\n",
      "Epoch 670/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0414 - mse: 0.0035 - val_loss: 0.0040 - val_mae: 0.0413 - val_mse: 0.0040\n",
      "Epoch 671/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0039 - mae: 0.0435 - mse: 0.0039 - val_loss: 0.0037 - val_mae: 0.0394 - val_mse: 0.0037\n",
      "Epoch 672/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0414 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0391 - val_mse: 0.0037\n",
      "Epoch 673/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0411 - mse: 0.0037 - val_loss: 0.0037 - val_mae: 0.0388 - val_mse: 0.0037\n",
      "Epoch 674/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0390 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0366 - val_mse: 0.0035\n",
      "Epoch 675/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0386 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0372 - val_mse: 0.0036\n",
      "Epoch 676/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0394 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0370 - val_mse: 0.0036\n",
      "Epoch 677/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0386 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0368 - val_mse: 0.0034\n",
      "Epoch 678/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0379 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0359 - val_mse: 0.0034\n",
      "Epoch 679/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0373 - mse: 0.0032 - val_loss: 0.0036 - val_mae: 0.0363 - val_mse: 0.0036\n",
      "Epoch 680/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0379 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0367 - val_mse: 0.0035\n",
      "Epoch 681/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0385 - mse: 0.0035 - val_loss: 0.0037 - val_mae: 0.0386 - val_mse: 0.0037\n",
      "Epoch 682/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0391 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0376 - val_mse: 0.0036\n",
      "Epoch 683/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0403 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0362 - val_mse: 0.0035\n",
      "Epoch 684/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0371 - mse: 0.0033 - val_loss: 0.0033 - val_mae: 0.0360 - val_mse: 0.0033\n",
      "Epoch 685/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0387 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0369 - val_mse: 0.0036\n",
      "Epoch 686/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0387 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0371 - val_mse: 0.0035\n",
      "Epoch 687/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0388 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0386 - val_mse: 0.0037\n",
      "Epoch 688/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0394 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0381 - val_mse: 0.0036\n",
      "Epoch 689/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0385 - mse: 0.0031 - val_loss: 0.0036 - val_mae: 0.0383 - val_mse: 0.0036\n",
      "Epoch 690/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0399 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0389 - val_mse: 0.0037\n",
      "Epoch 691/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0397 - mse: 0.0033 - val_loss: 0.0037 - val_mae: 0.0392 - val_mse: 0.0037\n",
      "Epoch 692/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0407 - mse: 0.0035 - val_loss: 0.0037 - val_mae: 0.0395 - val_mse: 0.0037\n",
      "Epoch 693/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0402 - mse: 0.0035 - val_loss: 0.0037 - val_mae: 0.0406 - val_mse: 0.0037\n",
      "Epoch 694/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0426 - mse: 0.0037 - val_loss: 0.0038 - val_mae: 0.0402 - val_mse: 0.0038\n",
      "Epoch 695/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0421 - mse: 0.0037 - val_loss: 0.0038 - val_mae: 0.0408 - val_mse: 0.0038\n",
      "Epoch 696/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0424 - mse: 0.0038 - val_loss: 0.0039 - val_mae: 0.0424 - val_mse: 0.0039\n",
      "Epoch 697/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0415 - mse: 0.0036 - val_loss: 0.0040 - val_mae: 0.0418 - val_mse: 0.0040\n",
      "Epoch 698/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0425 - mse: 0.0036 - val_loss: 0.0040 - val_mae: 0.0413 - val_mse: 0.0040\n",
      "Epoch 699/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0437 - mse: 0.0038 - val_loss: 0.0038 - val_mae: 0.0405 - val_mse: 0.0038\n",
      "Epoch 700/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0419 - mse: 0.0037 - val_loss: 0.0037 - val_mae: 0.0379 - val_mse: 0.0037\n",
      "Epoch 701/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0393 - mse: 0.0034 - val_loss: 0.0040 - val_mae: 0.0412 - val_mse: 0.0040\n",
      "Epoch 702/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0426 - mse: 0.0037 - val_loss: 0.0038 - val_mae: 0.0386 - val_mse: 0.0038\n",
      "Epoch 703/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0403 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0378 - val_mse: 0.0035\n",
      "Epoch 704/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0397 - mse: 0.0035 - val_loss: 0.0037 - val_mae: 0.0390 - val_mse: 0.0037\n",
      "Epoch 705/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0389 - mse: 0.0033 - val_loss: 0.0037 - val_mae: 0.0401 - val_mse: 0.0037\n",
      "Epoch 706/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0398 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0386 - val_mse: 0.0035\n",
      "Epoch 707/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0384 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0375 - val_mse: 0.0036\n",
      "Epoch 708/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0396 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0373 - val_mse: 0.0036\n",
      "Epoch 709/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0400 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0383 - val_mse: 0.0036\n",
      "Epoch 710/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0410 - mse: 0.0036 - val_loss: 0.0037 - val_mae: 0.0399 - val_mse: 0.0037\n",
      "Epoch 711/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0420 - mse: 0.0037 - val_loss: 0.0042 - val_mae: 0.0456 - val_mse: 0.0042\n",
      "Epoch 712/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0039 - mae: 0.0448 - mse: 0.0039 - val_loss: 0.0048 - val_mae: 0.0488 - val_mse: 0.0048\n",
      "Epoch 713/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0458 - mse: 0.0038 - val_loss: 0.0042 - val_mae: 0.0457 - val_mse: 0.0042\n",
      "Epoch 714/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0040 - mae: 0.0454 - mse: 0.0040 - val_loss: 0.0038 - val_mae: 0.0407 - val_mse: 0.0038\n",
      "Epoch 715/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0412 - mse: 0.0035 - val_loss: 0.0038 - val_mae: 0.0394 - val_mse: 0.0038\n",
      "Epoch 716/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0406 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0390 - val_mse: 0.0035\n",
      "Epoch 717/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0411 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0382 - val_mse: 0.0035\n",
      "Epoch 718/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0399 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0390 - val_mse: 0.0036\n",
      "Epoch 719/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0421 - mse: 0.0038 - val_loss: 0.0036 - val_mae: 0.0382 - val_mse: 0.0036\n",
      "Epoch 720/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0398 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0394 - val_mse: 0.0036\n",
      "Epoch 721/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0412 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0380 - val_mse: 0.0036\n",
      "Epoch 722/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0405 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0383 - val_mse: 0.0036\n",
      "Epoch 723/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0400 - mse: 0.0033 - val_loss: 0.0037 - val_mae: 0.0390 - val_mse: 0.0037\n",
      "Epoch 724/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0408 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0378 - val_mse: 0.0036\n",
      "Epoch 725/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0392 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0383 - val_mse: 0.0035\n",
      "Epoch 726/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0380 - mse: 0.0033 - val_loss: 0.0033 - val_mae: 0.0368 - val_mse: 0.0033\n",
      "Epoch 727/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0373 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0372 - val_mse: 0.0034\n",
      "Epoch 728/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0380 - mse: 0.0031 - val_loss: 0.0036 - val_mae: 0.0366 - val_mse: 0.0036\n",
      "Epoch 729/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0379 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0370 - val_mse: 0.0034\n",
      "Epoch 730/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0368 - mse: 0.0031 - val_loss: 0.0036 - val_mae: 0.0369 - val_mse: 0.0036\n",
      "Epoch 731/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0389 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0366 - val_mse: 0.0035\n",
      "Epoch 732/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0382 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 733/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0388 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 734/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0380 - mse: 0.0032 - val_loss: 0.0036 - val_mae: 0.0371 - val_mse: 0.0036\n",
      "Epoch 735/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0388 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0376 - val_mse: 0.0034\n",
      "Epoch 736/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0387 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0359 - val_mse: 0.0035\n",
      "Epoch 737/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0384 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0363 - val_mse: 0.0035\n",
      "Epoch 738/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0383 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0369 - val_mse: 0.0035\n",
      "Epoch 739/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0392 - mse: 0.0033 - val_loss: 0.0037 - val_mae: 0.0387 - val_mse: 0.0037\n",
      "Epoch 740/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0398 - mse: 0.0035 - val_loss: 0.0038 - val_mae: 0.0388 - val_mse: 0.0038\n",
      "Epoch 741/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0418 - mse: 0.0038 - val_loss: 0.0037 - val_mae: 0.0373 - val_mse: 0.0037\n",
      "Epoch 742/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0407 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0368 - val_mse: 0.0036\n",
      "Epoch 743/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0399 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0368 - val_mse: 0.0036\n",
      "Epoch 744/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0390 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0366 - val_mse: 0.0034\n",
      "Epoch 745/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0380 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0362 - val_mse: 0.0034\n",
      "Epoch 746/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0371 - mse: 0.0032 - val_loss: 0.0036 - val_mae: 0.0378 - val_mse: 0.0036\n",
      "Epoch 747/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0385 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0366 - val_mse: 0.0035\n",
      "Epoch 748/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0386 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0368 - val_mse: 0.0034\n",
      "Epoch 749/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0360 - mse: 0.0030 - val_loss: 0.0034 - val_mae: 0.0367 - val_mse: 0.0034\n",
      "Epoch 750/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0388 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0370 - val_mse: 0.0034\n",
      "Epoch 751/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0376 - mse: 0.0032 - val_loss: 0.0036 - val_mae: 0.0373 - val_mse: 0.0036\n",
      "Epoch 752/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0377 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0365 - val_mse: 0.0034\n",
      "Epoch 753/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0374 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0355 - val_mse: 0.0034\n",
      "Epoch 754/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0379 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 755/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0385 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0356 - val_mse: 0.0035\n",
      "Epoch 756/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0380 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0365 - val_mse: 0.0035\n",
      "Epoch 757/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0378 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0359 - val_mse: 0.0034\n",
      "Epoch 758/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0385 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0379 - val_mse: 0.0037\n",
      "Epoch 759/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0376 - mse: 0.0032 - val_loss: 0.0037 - val_mae: 0.0367 - val_mse: 0.0037\n",
      "Epoch 760/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0379 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0362 - val_mse: 0.0034\n",
      "Epoch 761/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0376 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0373 - val_mse: 0.0035\n",
      "Epoch 762/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0381 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0370 - val_mse: 0.0034\n",
      "Epoch 763/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0375 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0370 - val_mse: 0.0034\n",
      "Epoch 764/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0391 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0375 - val_mse: 0.0036\n",
      "Epoch 765/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0400 - mse: 0.0035 - val_loss: 0.0038 - val_mae: 0.0387 - val_mse: 0.0038\n",
      "Epoch 766/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0396 - mse: 0.0036 - val_loss: 0.0038 - val_mae: 0.0385 - val_mse: 0.0038\n",
      "Epoch 767/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0384 - mse: 0.0034 - val_loss: 0.0038 - val_mae: 0.0374 - val_mse: 0.0038\n",
      "Epoch 768/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0380 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0367 - val_mse: 0.0034\n",
      "Epoch 769/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0376 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0370 - val_mse: 0.0034\n",
      "Epoch 770/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0384 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0370 - val_mse: 0.0034\n",
      "Epoch 771/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0393 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0369 - val_mse: 0.0035\n",
      "Epoch 772/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0382 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0371 - val_mse: 0.0034\n",
      "Epoch 773/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0392 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0372 - val_mse: 0.0035\n",
      "Epoch 774/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0390 - mse: 0.0033 - val_loss: 0.0037 - val_mae: 0.0376 - val_mse: 0.0037\n",
      "Epoch 775/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0400 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0361 - val_mse: 0.0034\n",
      "Epoch 776/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0400 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0362 - val_mse: 0.0034\n",
      "Epoch 777/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0396 - mse: 0.0035 - val_loss: 0.0033 - val_mae: 0.0363 - val_mse: 0.0033\n",
      "Epoch 778/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0391 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0372 - val_mse: 0.0035\n",
      "Epoch 779/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0383 - mse: 0.0032 - val_loss: 0.0039 - val_mae: 0.0376 - val_mse: 0.0039\n",
      "Epoch 780/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0041 - mae: 0.0419 - mse: 0.0041 - val_loss: 0.0036 - val_mae: 0.0372 - val_mse: 0.0036\n",
      "Epoch 781/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0404 - mse: 0.0034 - val_loss: 0.0042 - val_mae: 0.0411 - val_mse: 0.0042\n",
      "Epoch 782/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0040 - mae: 0.0426 - mse: 0.0040 - val_loss: 0.0037 - val_mae: 0.0377 - val_mse: 0.0037\n",
      "Epoch 783/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0039 - mae: 0.0417 - mse: 0.0039 - val_loss: 0.0037 - val_mae: 0.0384 - val_mse: 0.0037\n",
      "Epoch 784/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0418 - mse: 0.0038 - val_loss: 0.0037 - val_mae: 0.0373 - val_mse: 0.0037\n",
      "Epoch 785/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0403 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0361 - val_mse: 0.0035\n",
      "Epoch 786/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0386 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0362 - val_mse: 0.0034\n",
      "Epoch 787/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0393 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0365 - val_mse: 0.0034\n",
      "Epoch 788/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0378 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0365 - val_mse: 0.0034\n",
      "Epoch 789/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0392 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0361 - val_mse: 0.0035\n",
      "Epoch 790/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0407 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0389 - val_mse: 0.0036\n",
      "Epoch 791/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0396 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0362 - val_mse: 0.0035\n",
      "Epoch 792/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0400 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0361 - val_mse: 0.0034\n",
      "Epoch 793/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0388 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0366 - val_mse: 0.0035\n",
      "Epoch 794/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0393 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0373 - val_mse: 0.0034\n",
      "Epoch 795/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0391 - mse: 0.0035 - val_loss: 0.0033 - val_mae: 0.0365 - val_mse: 0.0033\n",
      "Epoch 796/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0401 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0368 - val_mse: 0.0036\n",
      "Epoch 797/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0397 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0370 - val_mse: 0.0035\n",
      "Epoch 798/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0404 - mse: 0.0037 - val_loss: 0.0037 - val_mae: 0.0373 - val_mse: 0.0037\n",
      "Epoch 799/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0385 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0377 - val_mse: 0.0035\n",
      "Epoch 800/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0410 - mse: 0.0035 - val_loss: 0.0037 - val_mae: 0.0365 - val_mse: 0.0037\n",
      "Epoch 801/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0384 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0373 - val_mse: 0.0035\n",
      "Epoch 802/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0377 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0371 - val_mse: 0.0034\n",
      "Epoch 803/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0385 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0360 - val_mse: 0.0035\n",
      "Epoch 804/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0386 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0358 - val_mse: 0.0034\n",
      "Epoch 805/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0396 - mse: 0.0038 - val_loss: 0.0033 - val_mae: 0.0359 - val_mse: 0.0033\n",
      "Epoch 806/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0377 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0380 - val_mse: 0.0034\n",
      "Epoch 807/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0388 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0360 - val_mse: 0.0033\n",
      "Epoch 808/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0390 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0355 - val_mse: 0.0034\n",
      "Epoch 809/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0367 - mse: 0.0031 - val_loss: 0.0033 - val_mae: 0.0363 - val_mse: 0.0033\n",
      "Epoch 810/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0380 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0356 - val_mse: 0.0034\n",
      "Epoch 811/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0393 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0361 - val_mse: 0.0034\n",
      "Epoch 812/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0377 - mse: 0.0033 - val_loss: 0.0033 - val_mae: 0.0362 - val_mse: 0.0033\n",
      "Epoch 813/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0366 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0370 - val_mse: 0.0034\n",
      "Epoch 814/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0390 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 815/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0383 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0364 - val_mse: 0.0034\n",
      "Epoch 816/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0394 - mse: 0.0038 - val_loss: 0.0034 - val_mae: 0.0357 - val_mse: 0.0034\n",
      "Epoch 817/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0372 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0351 - val_mse: 0.0034\n",
      "Epoch 818/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0376 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0355 - val_mse: 0.0035\n",
      "Epoch 819/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0364 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0365 - val_mse: 0.0034\n",
      "Epoch 820/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0383 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0358 - val_mse: 0.0035\n",
      "Epoch 821/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0387 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0374 - val_mse: 0.0036\n",
      "Epoch 822/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0389 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0366 - val_mse: 0.0036\n",
      "Epoch 823/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0397 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0356 - val_mse: 0.0034\n",
      "Epoch 824/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0363 - mse: 0.0031 - val_loss: 0.0035 - val_mae: 0.0356 - val_mse: 0.0035\n",
      "Epoch 825/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0378 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0355 - val_mse: 0.0036\n",
      "Epoch 826/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0371 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0356 - val_mse: 0.0034\n",
      "Epoch 827/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0375 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0357 - val_mse: 0.0034\n",
      "Epoch 828/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0381 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0360 - val_mse: 0.0036\n",
      "Epoch 829/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0387 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 830/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0379 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0367 - val_mse: 0.0035\n",
      "Epoch 831/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0380 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0358 - val_mse: 0.0035\n",
      "Epoch 832/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0387 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 833/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0039 - mae: 0.0392 - mse: 0.0039 - val_loss: 0.0034 - val_mae: 0.0365 - val_mse: 0.0034\n",
      "Epoch 834/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0371 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0357 - val_mse: 0.0035\n",
      "Epoch 835/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0373 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0357 - val_mse: 0.0034\n",
      "Epoch 836/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0382 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0351 - val_mse: 0.0034\n",
      "Epoch 837/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0368 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0376 - val_mse: 0.0034\n",
      "Epoch 838/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0382 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0360 - val_mse: 0.0033\n",
      "Epoch 839/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0369 - mse: 0.0031 - val_loss: 0.0035 - val_mae: 0.0360 - val_mse: 0.0035\n",
      "Epoch 840/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0373 - mse: 0.0033 - val_loss: 0.0033 - val_mae: 0.0357 - val_mse: 0.0033\n",
      "Epoch 841/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0390 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0363 - val_mse: 0.0034\n",
      "Epoch 842/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0373 - mse: 0.0031 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 843/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0392 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0373 - val_mse: 0.0036\n",
      "Epoch 844/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0391 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0364 - val_mse: 0.0034\n",
      "Epoch 845/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0394 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0366 - val_mse: 0.0035\n",
      "Epoch 846/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0378 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0362 - val_mse: 0.0035\n",
      "Epoch 847/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0377 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0375 - val_mse: 0.0035\n",
      "Epoch 848/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0393 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0382 - val_mse: 0.0035\n",
      "Epoch 849/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0397 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0376 - val_mse: 0.0035\n",
      "Epoch 850/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0402 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0382 - val_mse: 0.0035\n",
      "Epoch 851/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0395 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0375 - val_mse: 0.0034\n",
      "Epoch 852/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0387 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0362 - val_mse: 0.0034\n",
      "Epoch 853/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0379 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0365 - val_mse: 0.0034\n",
      "Epoch 854/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0395 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0364 - val_mse: 0.0034\n",
      "Epoch 855/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0404 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0368 - val_mse: 0.0034\n",
      "Epoch 856/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0399 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0379 - val_mse: 0.0035\n",
      "Epoch 857/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0389 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0371 - val_mse: 0.0034\n",
      "Epoch 858/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0390 - mse: 0.0035 - val_loss: 0.0038 - val_mae: 0.0387 - val_mse: 0.0038\n",
      "Epoch 859/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0394 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0378 - val_mse: 0.0036\n",
      "Epoch 860/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0384 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0369 - val_mse: 0.0036\n",
      "Epoch 861/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0401 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0363 - val_mse: 0.0036\n",
      "Epoch 862/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0378 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0374 - val_mse: 0.0036\n",
      "Epoch 863/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0395 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0369 - val_mse: 0.0036\n",
      "Epoch 864/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0398 - mse: 0.0037 - val_loss: 0.0037 - val_mae: 0.0374 - val_mse: 0.0037\n",
      "Epoch 865/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0395 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0366 - val_mse: 0.0035\n",
      "Epoch 866/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0385 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 867/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0398 - mse: 0.0037 - val_loss: 0.0034 - val_mae: 0.0369 - val_mse: 0.0034\n",
      "Epoch 868/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0384 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0365 - val_mse: 0.0035\n",
      "Epoch 869/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0391 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0358 - val_mse: 0.0034\n",
      "Epoch 870/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0384 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0358 - val_mse: 0.0036\n",
      "Epoch 871/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0376 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 872/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0384 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0354 - val_mse: 0.0034\n",
      "Epoch 873/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0375 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0369 - val_mse: 0.0036\n",
      "Epoch 874/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0382 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0358 - val_mse: 0.0035\n",
      "Epoch 875/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0375 - mse: 0.0033 - val_loss: 0.0033 - val_mae: 0.0361 - val_mse: 0.0033\n",
      "Epoch 876/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0382 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0367 - val_mse: 0.0035\n",
      "Epoch 877/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0380 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0371 - val_mse: 0.0035\n",
      "Epoch 878/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0381 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0379 - val_mse: 0.0037\n",
      "Epoch 879/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0410 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0377 - val_mse: 0.0036\n",
      "Epoch 880/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0395 - mse: 0.0035 - val_loss: 0.0039 - val_mae: 0.0386 - val_mse: 0.0039\n",
      "Epoch 881/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0395 - mse: 0.0034 - val_loss: 0.0038 - val_mae: 0.0388 - val_mse: 0.0038\n",
      "Epoch 882/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0397 - mse: 0.0035 - val_loss: 0.0037 - val_mae: 0.0388 - val_mse: 0.0037\n",
      "Epoch 883/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0394 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0394 - val_mse: 0.0037\n",
      "Epoch 884/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0402 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0407 - val_mse: 0.0036\n",
      "Epoch 885/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0413 - mse: 0.0036 - val_loss: 0.0038 - val_mae: 0.0392 - val_mse: 0.0038\n",
      "Epoch 886/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0414 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0386 - val_mse: 0.0036\n",
      "Epoch 887/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0409 - mse: 0.0036 - val_loss: 0.0037 - val_mae: 0.0397 - val_mse: 0.0037\n",
      "Epoch 888/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0422 - mse: 0.0037 - val_loss: 0.0042 - val_mae: 0.0420 - val_mse: 0.0042\n",
      "Epoch 889/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0423 - mse: 0.0036 - val_loss: 0.0042 - val_mae: 0.0406 - val_mse: 0.0042\n",
      "Epoch 890/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0432 - mse: 0.0038 - val_loss: 0.0039 - val_mae: 0.0413 - val_mse: 0.0039\n",
      "Epoch 891/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0039 - mae: 0.0446 - mse: 0.0039 - val_loss: 0.0040 - val_mae: 0.0428 - val_mse: 0.0040\n",
      "Epoch 892/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0040 - mae: 0.0456 - mse: 0.0040 - val_loss: 0.0039 - val_mae: 0.0412 - val_mse: 0.0039\n",
      "Epoch 893/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0438 - mse: 0.0038 - val_loss: 0.0039 - val_mae: 0.0387 - val_mse: 0.0039\n",
      "Epoch 894/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0420 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0376 - val_mse: 0.0036\n",
      "Epoch 895/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0391 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0369 - val_mse: 0.0035\n",
      "Epoch 896/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0398 - mse: 0.0035 - val_loss: 0.0038 - val_mae: 0.0372 - val_mse: 0.0038\n",
      "Epoch 897/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0392 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0359 - val_mse: 0.0035\n",
      "Epoch 898/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0390 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0363 - val_mse: 0.0035\n",
      "Epoch 899/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0387 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0378 - val_mse: 0.0037\n",
      "Epoch 900/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0389 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0375 - val_mse: 0.0035\n",
      "Epoch 901/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0411 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 902/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0398 - mse: 0.0035 - val_loss: 0.0038 - val_mae: 0.0385 - val_mse: 0.0038\n",
      "Epoch 903/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0430 - mse: 0.0038 - val_loss: 0.0037 - val_mae: 0.0380 - val_mse: 0.0037\n",
      "Epoch 904/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0039 - mae: 0.0428 - mse: 0.0039 - val_loss: 0.0036 - val_mae: 0.0388 - val_mse: 0.0036\n",
      "Epoch 905/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0417 - mse: 0.0037 - val_loss: 0.0037 - val_mae: 0.0394 - val_mse: 0.0037\n",
      "Epoch 906/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0406 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0375 - val_mse: 0.0035\n",
      "Epoch 907/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0407 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0377 - val_mse: 0.0036\n",
      "Epoch 908/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0405 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0376 - val_mse: 0.0035\n",
      "Epoch 909/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0414 - mse: 0.0037 - val_loss: 0.0037 - val_mae: 0.0376 - val_mse: 0.0037\n",
      "Epoch 910/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0388 - mse: 0.0034 - val_loss: 0.0038 - val_mae: 0.0377 - val_mse: 0.0038\n",
      "Epoch 911/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0392 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0369 - val_mse: 0.0035\n",
      "Epoch 912/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0393 - mse: 0.0037 - val_loss: 0.0037 - val_mae: 0.0372 - val_mse: 0.0037\n",
      "Epoch 913/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0401 - mse: 0.0038 - val_loss: 0.0034 - val_mae: 0.0364 - val_mse: 0.0034\n",
      "Epoch 914/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0385 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0365 - val_mse: 0.0035\n",
      "Epoch 915/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0039 - mae: 0.0409 - mse: 0.0039 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 916/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0389 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0368 - val_mse: 0.0036\n",
      "Epoch 917/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0398 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 918/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0394 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0367 - val_mse: 0.0034\n",
      "Epoch 919/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0379 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0376 - val_mse: 0.0036\n",
      "Epoch 920/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0400 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0379 - val_mse: 0.0035\n",
      "Epoch 921/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0396 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0373 - val_mse: 0.0035\n",
      "Epoch 922/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0401 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0376 - val_mse: 0.0036\n",
      "Epoch 923/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0407 - mse: 0.0036 - val_loss: 0.0038 - val_mae: 0.0394 - val_mse: 0.0038\n",
      "Epoch 924/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0420 - mse: 0.0038 - val_loss: 0.0036 - val_mae: 0.0368 - val_mse: 0.0036\n",
      "Epoch 925/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0386 - mse: 0.0032 - val_loss: 0.0033 - val_mae: 0.0363 - val_mse: 0.0033\n",
      "Epoch 926/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mae: 0.0388 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0362 - val_mse: 0.0036\n",
      "Epoch 927/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0392 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0368 - val_mse: 0.0035\n",
      "Epoch 928/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0382 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0364 - val_mse: 0.0035\n",
      "Epoch 929/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0389 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0367 - val_mse: 0.0035\n",
      "Epoch 930/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0405 - mse: 0.0036 - val_loss: 0.0038 - val_mae: 0.0374 - val_mse: 0.0038\n",
      "Epoch 931/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0038 - mae: 0.0405 - mse: 0.0038 - val_loss: 0.0035 - val_mae: 0.0364 - val_mse: 0.0035\n",
      "Epoch 932/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0392 - mse: 0.0034 - val_loss: 0.0038 - val_mae: 0.0370 - val_mse: 0.0038\n",
      "Epoch 933/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0403 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0361 - val_mse: 0.0036\n",
      "Epoch 934/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0393 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0356 - val_mse: 0.0036\n",
      "Epoch 935/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0375 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0359 - val_mse: 0.0035\n",
      "Epoch 936/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0378 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0354 - val_mse: 0.0034\n",
      "Epoch 937/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0389 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0355 - val_mse: 0.0033\n",
      "Epoch 938/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0380 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0360 - val_mse: 0.0035\n",
      "Epoch 939/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0377 - mse: 0.0033 - val_loss: 0.0035 - val_mae: 0.0363 - val_mse: 0.0035\n",
      "Epoch 940/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0379 - mse: 0.0032 - val_loss: 0.0037 - val_mae: 0.0369 - val_mse: 0.0037\n",
      "Epoch 941/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0378 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0365 - val_mse: 0.0035\n",
      "Epoch 942/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0373 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0364 - val_mse: 0.0035\n",
      "Epoch 943/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0385 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0366 - val_mse: 0.0034\n",
      "Epoch 944/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0386 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0367 - val_mse: 0.0036\n",
      "Epoch 945/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0390 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0367 - val_mse: 0.0034\n",
      "Epoch 946/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0375 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0365 - val_mse: 0.0036\n",
      "Epoch 947/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0373 - mse: 0.0032 - val_loss: 0.0037 - val_mae: 0.0373 - val_mse: 0.0037\n",
      "Epoch 948/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - mae: 0.0377 - mse: 0.0035 - val_loss: 0.0042 - val_mae: 0.0399 - val_mse: 0.0042\n",
      "Epoch 949/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0375 - mse: 0.0036 - val_loss: 0.0040 - val_mae: 0.0393 - val_mse: 0.0040\n",
      "Epoch 950/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0374 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0380 - val_mse: 0.0036\n",
      "Epoch 951/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0389 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0370 - val_mse: 0.0036\n",
      "Epoch 952/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0375 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0370 - val_mse: 0.0036\n",
      "Epoch 953/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0402 - mse: 0.0038 - val_loss: 0.0037 - val_mae: 0.0370 - val_mse: 0.0037\n",
      "Epoch 954/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0393 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0366 - val_mse: 0.0036\n",
      "Epoch 955/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0367 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0368 - val_mse: 0.0036\n",
      "Epoch 956/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0370 - mse: 0.0033 - val_loss: 0.0033 - val_mae: 0.0360 - val_mse: 0.0033\n",
      "Epoch 957/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0379 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0363 - val_mse: 0.0034\n",
      "Epoch 958/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0359 - val_mse: 0.0035\n",
      "Epoch 959/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0039 - mae: 0.0389 - mse: 0.0039 - val_loss: 0.0035 - val_mae: 0.0365 - val_mse: 0.0035\n",
      "Epoch 960/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0360 - val_mse: 0.0035\n",
      "Epoch 961/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0387 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0363 - val_mse: 0.0034\n",
      "Epoch 962/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0034 - mae: 0.0385 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0356 - val_mse: 0.0033\n",
      "Epoch 963/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0037 - mae: 0.0398 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0358 - val_mse: 0.0035\n",
      "Epoch 964/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0031 - mae: 0.0371 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0366 - val_mse: 0.0034\n",
      "Epoch 965/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0394 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0362 - val_mse: 0.0035\n",
      "Epoch 966/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0380 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0358 - val_mse: 0.0033\n",
      "Epoch 967/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0032 - mae: 0.0371 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0355 - val_mse: 0.0034\n",
      "Epoch 968/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0372 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0354 - val_mse: 0.0034\n",
      "Epoch 969/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0387 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0361 - val_mse: 0.0033\n",
      "Epoch 970/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0395 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0359 - val_mse: 0.0033\n",
      "Epoch 971/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0385 - mse: 0.0035 - val_loss: 0.0033 - val_mae: 0.0369 - val_mse: 0.0033\n",
      "Epoch 972/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0406 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0360 - val_mse: 0.0034\n",
      "Epoch 973/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0404 - mse: 0.0036 - val_loss: 0.0033 - val_mae: 0.0357 - val_mse: 0.0033\n",
      "Epoch 974/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0377 - mse: 0.0032 - val_loss: 0.0034 - val_mae: 0.0372 - val_mse: 0.0034\n",
      "Epoch 975/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0408 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0366 - val_mse: 0.0035\n",
      "Epoch 976/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0394 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0365 - val_mse: 0.0035\n",
      "Epoch 977/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0390 - mse: 0.0033 - val_loss: 0.0033 - val_mae: 0.0371 - val_mse: 0.0033\n",
      "Epoch 978/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0387 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0369 - val_mse: 0.0034\n",
      "Epoch 979/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0390 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0365 - val_mse: 0.0034\n",
      "Epoch 980/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0381 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0367 - val_mse: 0.0034\n",
      "Epoch 981/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0389 - mse: 0.0035 - val_loss: 0.0033 - val_mae: 0.0374 - val_mse: 0.0033\n",
      "Epoch 982/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0375 - mse: 0.0030 - val_loss: 0.0034 - val_mae: 0.0368 - val_mse: 0.0034\n",
      "Epoch 983/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0397 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0370 - val_mse: 0.0034\n",
      "Epoch 984/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0390 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0393 - val_mse: 0.0036\n",
      "Epoch 985/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0040 - mae: 0.0432 - mse: 0.0040 - val_loss: 0.0035 - val_mae: 0.0364 - val_mse: 0.0035\n",
      "Epoch 986/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036 - mae: 0.0406 - mse: 0.0036 - val_loss: 0.0035 - val_mae: 0.0375 - val_mse: 0.0035\n",
      "Epoch 987/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0040 - mae: 0.0428 - mse: 0.0040 - val_loss: 0.0035 - val_mae: 0.0373 - val_mse: 0.0035\n",
      "Epoch 988/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0412 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0380 - val_mse: 0.0036\n",
      "Epoch 989/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0400 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0374 - val_mse: 0.0036\n",
      "Epoch 990/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0402 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0367 - val_mse: 0.0035\n",
      "Epoch 991/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0374 - mse: 0.0031 - val_loss: 0.0035 - val_mae: 0.0373 - val_mse: 0.0035\n",
      "Epoch 992/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0386 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0368 - val_mse: 0.0034\n",
      "Epoch 993/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0391 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0371 - val_mse: 0.0034\n",
      "Epoch 994/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0413 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0377 - val_mse: 0.0036\n",
      "Epoch 995/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0405 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0362 - val_mse: 0.0036\n",
      "Epoch 996/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0386 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0360 - val_mse: 0.0035\n",
      "Epoch 997/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0035 - mae: 0.0388 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0357 - val_mse: 0.0034\n",
      "Epoch 998/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0384 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0363 - val_mse: 0.0034\n",
      "Epoch 999/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0372 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0359 - val_mse: 0.0035\n",
      "Epoch 1000/1000\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034 - mae: 0.0371 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0358 - val_mse: 0.0035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ae266ddd90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ba6654",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab1c9d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "plt.plot(model.history.history[\"loss\"])\n",
    "plt.plot(model.history.history[\"val_loss\"])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fae9bc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "r2 score:  0.8788827631390324\n"
     ]
    }
   ],
   "source": [
    "# r2 score\n",
    "\n",
    "y_pred = model.predict(x_test) \n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"r2 score: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74dcae83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual:  [[0.01641266]\n",
      " [0.16060961]\n",
      " [0.        ]\n",
      " [0.00234467]\n",
      " [0.04220399]\n",
      " [0.58382181]\n",
      " [0.22391559]\n",
      " [0.00117233]\n",
      " [0.06682298]\n",
      " [0.1922626 ]]\n",
      "predicted:  [[0.01383723 0.07130415 0.01159398 0.01159398 0.01159398 0.4645714\n",
      "  0.4000977  0.01159398 0.07479145 0.32185715]]\n"
     ]
    }
   ],
   "source": [
    "print(\"actual: \", y_test[:10])\n",
    "print(\"predicted: \", y_pred[:10].T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de351437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual inverse scaled:  [[ 1.5 13.8  0.1  0.3  3.7 49.9 19.2  0.2  5.8 16.5]]\n",
      "predicted inverse scaled [[ 1.2803159  6.1822443  1.0889661  1.0889661  1.0889661 39.72794\n",
      "  34.228333   1.0889661  6.4797106 27.554415 ]]\n"
     ]
    }
   ],
   "source": [
    "# Print the results without scaling\n",
    "print(\"actual inverse scaled: \", scaler_target.inverse_transform(y_test[:10].T))\n",
    "print(\"predicted inverse scaled\", scaler_target.inverse_transform(y_pred[:10].T))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
